{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_collection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Importing libraries"
      ],
      "metadata": {
        "id": "j_zM615jfX59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-yuk5GYYcpF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Datasets"
      ],
      "metadata": {
        "id": "N64j1F9effGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/Movie_collection_train.csv\")\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "ALKR1svRZwPr",
        "outputId": "d1fb765b-33fe-4921-df0a-7c35b0ca7a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Collection  Marketin_expense  Production_expense  Multiplex_coverage  \\\n",
              "0         48000           20.1264               59.62               0.462   \n",
              "1         43200           20.5462               69.14               0.531   \n",
              "2         69400           20.5458               69.14               0.531   \n",
              "3         66800           20.6474               59.36               0.542   \n",
              "4         72400           21.3810               59.36               0.542   \n",
              "..          ...               ...                 ...                 ...   \n",
              "395       26200          194.3350               91.20               0.307   \n",
              "396       25000          137.4410               91.20               0.307   \n",
              "397       17000          173.4404               91.20               0.307   \n",
              "398       10000          787.0360               91.20               0.307   \n",
              "399       12600          218.3310               91.20               0.307   \n",
              "\n",
              "        Budget  Movie_length  Lead_ Actor_Rating  Lead_Actress_rating  \\\n",
              "0    36524.125         138.7               7.825                8.095   \n",
              "1    35668.655         152.4               7.505                7.650   \n",
              "2    39912.675         134.6               7.485                7.570   \n",
              "3    38873.890         119.3               6.895                7.035   \n",
              "4    39701.585         127.7               6.920                7.070   \n",
              "..         ...           ...                 ...                  ...   \n",
              "395  35946.405         172.3               8.980                9.260   \n",
              "396  35579.775         169.5               9.115                9.180   \n",
              "397  31924.585         172.4               9.135                9.230   \n",
              "398  30291.415         173.5               9.215                9.370   \n",
              "399  32507.860         151.3               9.150                9.380   \n",
              "\n",
              "     Director_rating  Producer_rating  Critic_rating  Trailer_views  \\\n",
              "0              7.910            7.995           7.94         527367   \n",
              "1              7.440            7.470           7.44         494055   \n",
              "2              7.495            7.515           7.44         547051   \n",
              "3              6.920            7.020           8.26         516279   \n",
              "4              6.815            7.070           8.26         531448   \n",
              "..               ...              ...            ...            ...   \n",
              "395            9.085            9.225           7.96         424127   \n",
              "396            9.100            9.255           6.96         390048   \n",
              "397            9.125            9.240           6.96         384688   \n",
              "398            9.105            9.330           6.96         291101   \n",
              "399            9.140            9.330           6.96         270691   \n",
              "\n",
              "     Time_taken  Twitter_hastags     Genre  Avg_age_actors MPAA_film_rating  \\\n",
              "0        109.60          223.840  Thriller              23               PG   \n",
              "1        146.64          243.456     Drama              42               PG   \n",
              "2        147.88         2022.400    Comedy              38               PG   \n",
              "3        185.36          225.344     Drama              45               PG   \n",
              "4        176.48          225.792     Drama              55               PG   \n",
              "..          ...              ...       ...             ...              ...   \n",
              "395      115.24          302.096    Action              29               PG   \n",
              "396      109.00          222.000  Thriller              24               PG   \n",
              "397      185.40          281.360    Comedy              22               PG   \n",
              "398      186.00          260.800     Drama              26               PG   \n",
              "399      134.52          281.008  Thriller              42               PG   \n",
              "\n",
              "     Num_multiplex 3D_available  \n",
              "0              494          YES  \n",
              "1              462           NO  \n",
              "2              458           NO  \n",
              "3              472          YES  \n",
              "4              395           NO  \n",
              "..             ...          ...  \n",
              "395            712           NO  \n",
              "396            685          YES  \n",
              "397            663           NO  \n",
              "398            653           NO  \n",
              "399            613           NO  \n",
              "\n",
              "[400 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61476e8a-fa53-40ad-b047-d314fe4c9871\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Collection</th>\n",
              "      <th>Marketin_expense</th>\n",
              "      <th>Production_expense</th>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Movie_length</th>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <th>Director_rating</th>\n",
              "      <th>Producer_rating</th>\n",
              "      <th>Critic_rating</th>\n",
              "      <th>Trailer_views</th>\n",
              "      <th>Time_taken</th>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <th>Genre</th>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <th>MPAA_film_rating</th>\n",
              "      <th>Num_multiplex</th>\n",
              "      <th>3D_available</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48000</td>\n",
              "      <td>20.1264</td>\n",
              "      <td>59.62</td>\n",
              "      <td>0.462</td>\n",
              "      <td>36524.125</td>\n",
              "      <td>138.7</td>\n",
              "      <td>7.825</td>\n",
              "      <td>8.095</td>\n",
              "      <td>7.910</td>\n",
              "      <td>7.995</td>\n",
              "      <td>7.94</td>\n",
              "      <td>527367</td>\n",
              "      <td>109.60</td>\n",
              "      <td>223.840</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>23</td>\n",
              "      <td>PG</td>\n",
              "      <td>494</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43200</td>\n",
              "      <td>20.5462</td>\n",
              "      <td>69.14</td>\n",
              "      <td>0.531</td>\n",
              "      <td>35668.655</td>\n",
              "      <td>152.4</td>\n",
              "      <td>7.505</td>\n",
              "      <td>7.650</td>\n",
              "      <td>7.440</td>\n",
              "      <td>7.470</td>\n",
              "      <td>7.44</td>\n",
              "      <td>494055</td>\n",
              "      <td>146.64</td>\n",
              "      <td>243.456</td>\n",
              "      <td>Drama</td>\n",
              "      <td>42</td>\n",
              "      <td>PG</td>\n",
              "      <td>462</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69400</td>\n",
              "      <td>20.5458</td>\n",
              "      <td>69.14</td>\n",
              "      <td>0.531</td>\n",
              "      <td>39912.675</td>\n",
              "      <td>134.6</td>\n",
              "      <td>7.485</td>\n",
              "      <td>7.570</td>\n",
              "      <td>7.495</td>\n",
              "      <td>7.515</td>\n",
              "      <td>7.44</td>\n",
              "      <td>547051</td>\n",
              "      <td>147.88</td>\n",
              "      <td>2022.400</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>38</td>\n",
              "      <td>PG</td>\n",
              "      <td>458</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66800</td>\n",
              "      <td>20.6474</td>\n",
              "      <td>59.36</td>\n",
              "      <td>0.542</td>\n",
              "      <td>38873.890</td>\n",
              "      <td>119.3</td>\n",
              "      <td>6.895</td>\n",
              "      <td>7.035</td>\n",
              "      <td>6.920</td>\n",
              "      <td>7.020</td>\n",
              "      <td>8.26</td>\n",
              "      <td>516279</td>\n",
              "      <td>185.36</td>\n",
              "      <td>225.344</td>\n",
              "      <td>Drama</td>\n",
              "      <td>45</td>\n",
              "      <td>PG</td>\n",
              "      <td>472</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72400</td>\n",
              "      <td>21.3810</td>\n",
              "      <td>59.36</td>\n",
              "      <td>0.542</td>\n",
              "      <td>39701.585</td>\n",
              "      <td>127.7</td>\n",
              "      <td>6.920</td>\n",
              "      <td>7.070</td>\n",
              "      <td>6.815</td>\n",
              "      <td>7.070</td>\n",
              "      <td>8.26</td>\n",
              "      <td>531448</td>\n",
              "      <td>176.48</td>\n",
              "      <td>225.792</td>\n",
              "      <td>Drama</td>\n",
              "      <td>55</td>\n",
              "      <td>PG</td>\n",
              "      <td>395</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>26200</td>\n",
              "      <td>194.3350</td>\n",
              "      <td>91.20</td>\n",
              "      <td>0.307</td>\n",
              "      <td>35946.405</td>\n",
              "      <td>172.3</td>\n",
              "      <td>8.980</td>\n",
              "      <td>9.260</td>\n",
              "      <td>9.085</td>\n",
              "      <td>9.225</td>\n",
              "      <td>7.96</td>\n",
              "      <td>424127</td>\n",
              "      <td>115.24</td>\n",
              "      <td>302.096</td>\n",
              "      <td>Action</td>\n",
              "      <td>29</td>\n",
              "      <td>PG</td>\n",
              "      <td>712</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>25000</td>\n",
              "      <td>137.4410</td>\n",
              "      <td>91.20</td>\n",
              "      <td>0.307</td>\n",
              "      <td>35579.775</td>\n",
              "      <td>169.5</td>\n",
              "      <td>9.115</td>\n",
              "      <td>9.180</td>\n",
              "      <td>9.100</td>\n",
              "      <td>9.255</td>\n",
              "      <td>6.96</td>\n",
              "      <td>390048</td>\n",
              "      <td>109.00</td>\n",
              "      <td>222.000</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>24</td>\n",
              "      <td>PG</td>\n",
              "      <td>685</td>\n",
              "      <td>YES</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>17000</td>\n",
              "      <td>173.4404</td>\n",
              "      <td>91.20</td>\n",
              "      <td>0.307</td>\n",
              "      <td>31924.585</td>\n",
              "      <td>172.4</td>\n",
              "      <td>9.135</td>\n",
              "      <td>9.230</td>\n",
              "      <td>9.125</td>\n",
              "      <td>9.240</td>\n",
              "      <td>6.96</td>\n",
              "      <td>384688</td>\n",
              "      <td>185.40</td>\n",
              "      <td>281.360</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>22</td>\n",
              "      <td>PG</td>\n",
              "      <td>663</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>10000</td>\n",
              "      <td>787.0360</td>\n",
              "      <td>91.20</td>\n",
              "      <td>0.307</td>\n",
              "      <td>30291.415</td>\n",
              "      <td>173.5</td>\n",
              "      <td>9.215</td>\n",
              "      <td>9.370</td>\n",
              "      <td>9.105</td>\n",
              "      <td>9.330</td>\n",
              "      <td>6.96</td>\n",
              "      <td>291101</td>\n",
              "      <td>186.00</td>\n",
              "      <td>260.800</td>\n",
              "      <td>Drama</td>\n",
              "      <td>26</td>\n",
              "      <td>PG</td>\n",
              "      <td>653</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>12600</td>\n",
              "      <td>218.3310</td>\n",
              "      <td>91.20</td>\n",
              "      <td>0.307</td>\n",
              "      <td>32507.860</td>\n",
              "      <td>151.3</td>\n",
              "      <td>9.150</td>\n",
              "      <td>9.380</td>\n",
              "      <td>9.140</td>\n",
              "      <td>9.330</td>\n",
              "      <td>6.96</td>\n",
              "      <td>270691</td>\n",
              "      <td>134.52</td>\n",
              "      <td>281.008</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>42</td>\n",
              "      <td>PG</td>\n",
              "      <td>613</td>\n",
              "      <td>NO</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>400 rows × 19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61476e8a-fa53-40ad-b047-d314fe4c9871')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61476e8a-fa53-40ad-b047-d314fe4c9871 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61476e8a-fa53-40ad-b047-d314fe4c9871');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data preprocessing"
      ],
      "metadata": {
        "id": "AIdB9cXsfpjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####EDD (Extended Data Dictionary)"
      ],
      "metadata": {
        "id": "v3spxl70f1Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "yPgEOARlaBBA",
        "outputId": "4b6a1d96-8fed-489d-81bb-ac6a831204fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Collection  Marketin_expense  Production_expense  \\\n",
              "count     400.000000        400.000000          400.000000   \n",
              "mean    48646.500000         55.017180           73.832700   \n",
              "std     18308.499136        119.755634           13.023426   \n",
              "min     10000.000000         20.126400           55.920000   \n",
              "25%     37800.000000         21.321950           63.250000   \n",
              "50%     45000.000000         23.214700           69.030000   \n",
              "75%     56500.000000         34.638300           82.840000   \n",
              "max    100000.000000       1799.524000          106.300000   \n",
              "\n",
              "       Multiplex_coverage        Budget  Movie_length  Lead_ Actor_Rating  \\\n",
              "count          400.000000    400.000000    400.000000          400.000000   \n",
              "mean             0.469881  35197.771537    137.581750            7.810275   \n",
              "std              0.113920   4075.766926     28.990673            1.088694   \n",
              "min              0.129000  19781.355000     76.400000            3.840000   \n",
              "25%              0.419000  32721.727500    111.175000            7.092500   \n",
              "50%              0.494500  34593.762500    142.250000            7.995000   \n",
              "75%              0.558000  37142.118750    165.400000            8.725000   \n",
              "max              0.615000  48772.900000    173.500000            9.435000   \n",
              "\n",
              "       Lead_Actress_rating  Director_rating  Producer_rating  Critic_rating  \\\n",
              "count           400.000000       400.000000       400.000000     400.000000   \n",
              "mean              7.982812         7.813375         7.993887       7.894100   \n",
              "std               1.089923         1.093581         1.088619       0.672413   \n",
              "min               4.035000         3.840000         4.030000       6.600000   \n",
              "25%               7.252500         7.123750         7.273750       7.320000   \n",
              "50%               8.157500         7.990000         8.140000       7.960000   \n",
              "75%               8.912500         8.740000         8.931250       8.400000   \n",
              "max               9.540000         9.425000         9.635000       9.400000   \n",
              "\n",
              "       Trailer_views  Time_taken  Twitter_hastags  Avg_age_actors  \\\n",
              "count     400.000000  392.000000       400.000000      400.000000   \n",
              "mean   463223.567500  157.790000       258.083840       38.715000   \n",
              "std     65225.567649   31.723517        94.621476       12.651043   \n",
              "min    215432.000000    0.000000       201.632000        3.000000   \n",
              "25%    436793.500000  133.360000       223.804000       26.000000   \n",
              "50%    474930.000000  159.720000       246.680000       39.000000   \n",
              "75%    507690.500000  183.210000       283.444000       50.000000   \n",
              "max    567784.000000  217.520000      2022.400000       60.000000   \n",
              "\n",
              "       Num_multiplex  \n",
              "count     400.000000  \n",
              "mean      523.650000  \n",
              "std       103.661283  \n",
              "min       333.000000  \n",
              "25%       451.000000  \n",
              "50%       510.000000  \n",
              "75%       571.000000  \n",
              "max       868.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32585886-bff3-44b1-9491-21753c0b8d9c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Collection</th>\n",
              "      <th>Marketin_expense</th>\n",
              "      <th>Production_expense</th>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Movie_length</th>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <th>Director_rating</th>\n",
              "      <th>Producer_rating</th>\n",
              "      <th>Critic_rating</th>\n",
              "      <th>Trailer_views</th>\n",
              "      <th>Time_taken</th>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <th>Num_multiplex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>48646.500000</td>\n",
              "      <td>55.017180</td>\n",
              "      <td>73.832700</td>\n",
              "      <td>0.469881</td>\n",
              "      <td>35197.771537</td>\n",
              "      <td>137.581750</td>\n",
              "      <td>7.810275</td>\n",
              "      <td>7.982812</td>\n",
              "      <td>7.813375</td>\n",
              "      <td>7.993887</td>\n",
              "      <td>7.894100</td>\n",
              "      <td>463223.567500</td>\n",
              "      <td>157.790000</td>\n",
              "      <td>258.083840</td>\n",
              "      <td>38.715000</td>\n",
              "      <td>523.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>18308.499136</td>\n",
              "      <td>119.755634</td>\n",
              "      <td>13.023426</td>\n",
              "      <td>0.113920</td>\n",
              "      <td>4075.766926</td>\n",
              "      <td>28.990673</td>\n",
              "      <td>1.088694</td>\n",
              "      <td>1.089923</td>\n",
              "      <td>1.093581</td>\n",
              "      <td>1.088619</td>\n",
              "      <td>0.672413</td>\n",
              "      <td>65225.567649</td>\n",
              "      <td>31.723517</td>\n",
              "      <td>94.621476</td>\n",
              "      <td>12.651043</td>\n",
              "      <td>103.661283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>20.126400</td>\n",
              "      <td>55.920000</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>19781.355000</td>\n",
              "      <td>76.400000</td>\n",
              "      <td>3.840000</td>\n",
              "      <td>4.035000</td>\n",
              "      <td>3.840000</td>\n",
              "      <td>4.030000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>215432.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>201.632000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>333.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>37800.000000</td>\n",
              "      <td>21.321950</td>\n",
              "      <td>63.250000</td>\n",
              "      <td>0.419000</td>\n",
              "      <td>32721.727500</td>\n",
              "      <td>111.175000</td>\n",
              "      <td>7.092500</td>\n",
              "      <td>7.252500</td>\n",
              "      <td>7.123750</td>\n",
              "      <td>7.273750</td>\n",
              "      <td>7.320000</td>\n",
              "      <td>436793.500000</td>\n",
              "      <td>133.360000</td>\n",
              "      <td>223.804000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>451.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>45000.000000</td>\n",
              "      <td>23.214700</td>\n",
              "      <td>69.030000</td>\n",
              "      <td>0.494500</td>\n",
              "      <td>34593.762500</td>\n",
              "      <td>142.250000</td>\n",
              "      <td>7.995000</td>\n",
              "      <td>8.157500</td>\n",
              "      <td>7.990000</td>\n",
              "      <td>8.140000</td>\n",
              "      <td>7.960000</td>\n",
              "      <td>474930.000000</td>\n",
              "      <td>159.720000</td>\n",
              "      <td>246.680000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>56500.000000</td>\n",
              "      <td>34.638300</td>\n",
              "      <td>82.840000</td>\n",
              "      <td>0.558000</td>\n",
              "      <td>37142.118750</td>\n",
              "      <td>165.400000</td>\n",
              "      <td>8.725000</td>\n",
              "      <td>8.912500</td>\n",
              "      <td>8.740000</td>\n",
              "      <td>8.931250</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>507690.500000</td>\n",
              "      <td>183.210000</td>\n",
              "      <td>283.444000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>571.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>1799.524000</td>\n",
              "      <td>106.300000</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>48772.900000</td>\n",
              "      <td>173.500000</td>\n",
              "      <td>9.435000</td>\n",
              "      <td>9.540000</td>\n",
              "      <td>9.425000</td>\n",
              "      <td>9.635000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>567784.000000</td>\n",
              "      <td>217.520000</td>\n",
              "      <td>2022.400000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>868.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32585886-bff3-44b1-9491-21753c0b8d9c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32585886-bff3-44b1-9491-21753c0b8d9c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32585886-bff3-44b1-9491-21753c0b8d9c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Outliers detection and Treatment"
      ],
      "metadata": {
        "id": "DqHG_BgPgy8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df.Marketin_expense,df.Collection)\n",
        "plt.xlabel('marketing expenses')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "qtHVwTImpdJq",
        "outputId": "4be6f78d-f71b-4751-a5c7-6acd37e60883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'marketing expenses')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df.Twitter_hastags,df.Collection)\n",
        "plt.xlabel('Twitter_hastags')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "bIylbzGtq6Ye",
        "outputId": "c99dbd4a-efa3-4699-8106-a1a81c166629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Twitter_hastags')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uv=np.percentile(df.Twitter_hastags,[99])[0]\n",
        "df.Twitter_hastags[df.Twitter_hastags>3*uv]=3*uv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fskmwHH1Ls3",
        "outputId": "822e5d26-fa5d-4985-dba6-19cda643ea59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EDD after outliers treatment\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "TbFpaKgrSAnC",
        "outputId": "138fd905-0266-4cb1-dec1-fa61e439762f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Collection  Marketin_expense  Production_expense  \\\n",
              "count     400.000000        400.000000          400.000000   \n",
              "mean    48646.500000         55.017180           73.832700   \n",
              "std     18308.499136        119.755634           13.023426   \n",
              "min     10000.000000         20.126400           55.920000   \n",
              "25%     37800.000000         21.321950           63.250000   \n",
              "50%     45000.000000         23.214700           69.030000   \n",
              "75%     56500.000000         34.638300           82.840000   \n",
              "max    100000.000000       1799.524000          106.300000   \n",
              "\n",
              "       Multiplex_coverage        Budget  Movie_length  Lead_ Actor_Rating  \\\n",
              "count          400.000000    400.000000    400.000000          400.000000   \n",
              "mean             0.469881  35197.771537    137.581750            7.810275   \n",
              "std              0.113920   4075.766926     28.990673            1.088694   \n",
              "min              0.129000  19781.355000     76.400000            3.840000   \n",
              "25%              0.419000  32721.727500    111.175000            7.092500   \n",
              "50%              0.494500  34593.762500    142.250000            7.995000   \n",
              "75%              0.558000  37142.118750    165.400000            8.725000   \n",
              "max              0.615000  48772.900000    173.500000            9.435000   \n",
              "\n",
              "       Lead_Actress_rating  Director_rating  Producer_rating  Critic_rating  \\\n",
              "count           400.000000       400.000000       400.000000     400.000000   \n",
              "mean              7.982812         7.813375         7.993887       7.894100   \n",
              "std               1.089923         1.093581         1.088619       0.672413   \n",
              "min               4.035000         3.840000         4.030000       6.600000   \n",
              "25%               7.252500         7.123750         7.273750       7.320000   \n",
              "50%               8.157500         7.990000         8.140000       7.960000   \n",
              "75%               8.912500         8.740000         8.931250       8.400000   \n",
              "max               9.540000         9.425000         9.635000       9.400000   \n",
              "\n",
              "       Trailer_views  Time_taken  Twitter_hastags  Avg_age_actors  \\\n",
              "count     400.000000  392.000000       400.000000      400.000000   \n",
              "mean   463223.567500  157.790000       255.337840       38.715000   \n",
              "std     65225.567649   31.723517        47.492326       12.651043   \n",
              "min    215432.000000    0.000000       201.632000        3.000000   \n",
              "25%    436793.500000  133.360000       223.804000       26.000000   \n",
              "50%    474930.000000  159.720000       246.680000       39.000000   \n",
              "75%    507690.500000  183.210000       283.444000       50.000000   \n",
              "max    567784.000000  217.520000       924.000000       60.000000   \n",
              "\n",
              "       Num_multiplex  \n",
              "count     400.000000  \n",
              "mean      523.650000  \n",
              "std       103.661283  \n",
              "min       333.000000  \n",
              "25%       451.000000  \n",
              "50%       510.000000  \n",
              "75%       571.000000  \n",
              "max       868.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3b41160-773e-4298-bf2f-1139fc5ba4e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Collection</th>\n",
              "      <th>Marketin_expense</th>\n",
              "      <th>Production_expense</th>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Movie_length</th>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <th>Director_rating</th>\n",
              "      <th>Producer_rating</th>\n",
              "      <th>Critic_rating</th>\n",
              "      <th>Trailer_views</th>\n",
              "      <th>Time_taken</th>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <th>Num_multiplex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>400.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>48646.500000</td>\n",
              "      <td>55.017180</td>\n",
              "      <td>73.832700</td>\n",
              "      <td>0.469881</td>\n",
              "      <td>35197.771537</td>\n",
              "      <td>137.581750</td>\n",
              "      <td>7.810275</td>\n",
              "      <td>7.982812</td>\n",
              "      <td>7.813375</td>\n",
              "      <td>7.993887</td>\n",
              "      <td>7.894100</td>\n",
              "      <td>463223.567500</td>\n",
              "      <td>157.790000</td>\n",
              "      <td>255.337840</td>\n",
              "      <td>38.715000</td>\n",
              "      <td>523.650000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>18308.499136</td>\n",
              "      <td>119.755634</td>\n",
              "      <td>13.023426</td>\n",
              "      <td>0.113920</td>\n",
              "      <td>4075.766926</td>\n",
              "      <td>28.990673</td>\n",
              "      <td>1.088694</td>\n",
              "      <td>1.089923</td>\n",
              "      <td>1.093581</td>\n",
              "      <td>1.088619</td>\n",
              "      <td>0.672413</td>\n",
              "      <td>65225.567649</td>\n",
              "      <td>31.723517</td>\n",
              "      <td>47.492326</td>\n",
              "      <td>12.651043</td>\n",
              "      <td>103.661283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>10000.000000</td>\n",
              "      <td>20.126400</td>\n",
              "      <td>55.920000</td>\n",
              "      <td>0.129000</td>\n",
              "      <td>19781.355000</td>\n",
              "      <td>76.400000</td>\n",
              "      <td>3.840000</td>\n",
              "      <td>4.035000</td>\n",
              "      <td>3.840000</td>\n",
              "      <td>4.030000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>215432.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>201.632000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>333.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>37800.000000</td>\n",
              "      <td>21.321950</td>\n",
              "      <td>63.250000</td>\n",
              "      <td>0.419000</td>\n",
              "      <td>32721.727500</td>\n",
              "      <td>111.175000</td>\n",
              "      <td>7.092500</td>\n",
              "      <td>7.252500</td>\n",
              "      <td>7.123750</td>\n",
              "      <td>7.273750</td>\n",
              "      <td>7.320000</td>\n",
              "      <td>436793.500000</td>\n",
              "      <td>133.360000</td>\n",
              "      <td>223.804000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>451.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>45000.000000</td>\n",
              "      <td>23.214700</td>\n",
              "      <td>69.030000</td>\n",
              "      <td>0.494500</td>\n",
              "      <td>34593.762500</td>\n",
              "      <td>142.250000</td>\n",
              "      <td>7.995000</td>\n",
              "      <td>8.157500</td>\n",
              "      <td>7.990000</td>\n",
              "      <td>8.140000</td>\n",
              "      <td>7.960000</td>\n",
              "      <td>474930.000000</td>\n",
              "      <td>159.720000</td>\n",
              "      <td>246.680000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>510.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>56500.000000</td>\n",
              "      <td>34.638300</td>\n",
              "      <td>82.840000</td>\n",
              "      <td>0.558000</td>\n",
              "      <td>37142.118750</td>\n",
              "      <td>165.400000</td>\n",
              "      <td>8.725000</td>\n",
              "      <td>8.912500</td>\n",
              "      <td>8.740000</td>\n",
              "      <td>8.931250</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>507690.500000</td>\n",
              "      <td>183.210000</td>\n",
              "      <td>283.444000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>571.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>1799.524000</td>\n",
              "      <td>106.300000</td>\n",
              "      <td>0.615000</td>\n",
              "      <td>48772.900000</td>\n",
              "      <td>173.500000</td>\n",
              "      <td>9.435000</td>\n",
              "      <td>9.540000</td>\n",
              "      <td>9.425000</td>\n",
              "      <td>9.635000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>567784.000000</td>\n",
              "      <td>217.520000</td>\n",
              "      <td>924.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>868.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3b41160-773e-4298-bf2f-1139fc5ba4e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3b41160-773e-4298-bf2f-1139fc5ba4e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3b41160-773e-4298-bf2f-1139fc5ba4e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Detecting and imputing missing values"
      ],
      "metadata": {
        "id": "pmbIVdOchLt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#detecting the number of missing value in a particular column\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSWpXMpzpH1T",
        "outputId": "088ebd0d-cbc7-4e5f-9071-b764732a4981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Collection             0\n",
              "Marketin_expense       0\n",
              "Production_expense     0\n",
              "Multiplex_coverage     0\n",
              "Budget                 0\n",
              "Movie_length           0\n",
              "Lead_ Actor_Rating     0\n",
              "Lead_Actress_rating    0\n",
              "Director_rating        0\n",
              "Producer_rating        0\n",
              "Critic_rating          0\n",
              "Trailer_views          0\n",
              "Time_taken             8\n",
              "Twitter_hastags        0\n",
              "Genre                  0\n",
              "Avg_age_actors         0\n",
              "MPAA_film_rating       0\n",
              "Num_multiplex          0\n",
              "3D_available           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imputation of missing values\n",
        "df.Time_taken=df.Time_taken.fillna(df.Time_taken.mean())"
      ],
      "metadata": {
        "id": "hCPcthRKpNnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Variable Transformation"
      ],
      "metadata": {
        "id": "F-fCRnv2iZUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Marketin_expense=np.log(1+df.Marketin_expense)\n",
        "plt.scatter(df.Marketin_expense,df.Collection)\n",
        "plt.xlabel('marketing expenses')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "V5EgPMNhS2XX",
        "outputId": "4d43e960-d48a-427b-8795-4945af43b5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'marketing expenses')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Deletion of unnecessary variables"
      ],
      "metadata": {
        "id": "GyuSs8ilinb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del df['MPAA_film_rating']"
      ],
      "metadata": {
        "id": "BsLkIF24Y_cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Handling qualitative data\n",
        "###Dummy variable creation:"
      ],
      "metadata": {
        "id": "kdiDg0cViypn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.get_dummies(df)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QwpzTOFAauIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "6c3221ac-fbd2-46b5-8036-465878552b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Collection  Marketin_expense  Production_expense  Multiplex_coverage  \\\n",
              "0       48000          3.050523               59.62               0.462   \n",
              "1       43200          3.070199               69.14               0.531   \n",
              "2       69400          3.070181               69.14               0.531   \n",
              "3       66800          3.074885               59.36               0.542   \n",
              "4       72400          3.108212               59.36               0.542   \n",
              "\n",
              "      Budget  Movie_length  Lead_ Actor_Rating  Lead_Actress_rating  \\\n",
              "0  36524.125         138.7               7.825                8.095   \n",
              "1  35668.655         152.4               7.505                7.650   \n",
              "2  39912.675         134.6               7.485                7.570   \n",
              "3  38873.890         119.3               6.895                7.035   \n",
              "4  39701.585         127.7               6.920                7.070   \n",
              "\n",
              "   Director_rating  Producer_rating  ...  Time_taken  Twitter_hastags  \\\n",
              "0            7.910            7.995  ...      109.60          223.840   \n",
              "1            7.440            7.470  ...      146.64          243.456   \n",
              "2            7.495            7.515  ...      147.88          924.000   \n",
              "3            6.920            7.020  ...      185.36          225.344   \n",
              "4            6.815            7.070  ...      176.48          225.792   \n",
              "\n",
              "   Avg_age_actors  Num_multiplex  Genre_Action  Genre_Comedy  Genre_Drama  \\\n",
              "0              23            494             0             0            0   \n",
              "1              42            462             0             0            1   \n",
              "2              38            458             0             1            0   \n",
              "3              45            472             0             0            1   \n",
              "4              55            395             0             0            1   \n",
              "\n",
              "   Genre_Thriller  3D_available_NO  3D_available_YES  \n",
              "0               1                0                 1  \n",
              "1               0                1                 0  \n",
              "2               0                1                 0  \n",
              "3               0                0                 1  \n",
              "4               0                1                 0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ef83f3-26fd-4860-9e2e-d863146d2403\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Collection</th>\n",
              "      <th>Marketin_expense</th>\n",
              "      <th>Production_expense</th>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Movie_length</th>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <th>Director_rating</th>\n",
              "      <th>Producer_rating</th>\n",
              "      <th>...</th>\n",
              "      <th>Time_taken</th>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <th>Num_multiplex</th>\n",
              "      <th>Genre_Action</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Thriller</th>\n",
              "      <th>3D_available_NO</th>\n",
              "      <th>3D_available_YES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>48000</td>\n",
              "      <td>3.050523</td>\n",
              "      <td>59.62</td>\n",
              "      <td>0.462</td>\n",
              "      <td>36524.125</td>\n",
              "      <td>138.7</td>\n",
              "      <td>7.825</td>\n",
              "      <td>8.095</td>\n",
              "      <td>7.910</td>\n",
              "      <td>7.995</td>\n",
              "      <td>...</td>\n",
              "      <td>109.60</td>\n",
              "      <td>223.840</td>\n",
              "      <td>23</td>\n",
              "      <td>494</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>43200</td>\n",
              "      <td>3.070199</td>\n",
              "      <td>69.14</td>\n",
              "      <td>0.531</td>\n",
              "      <td>35668.655</td>\n",
              "      <td>152.4</td>\n",
              "      <td>7.505</td>\n",
              "      <td>7.650</td>\n",
              "      <td>7.440</td>\n",
              "      <td>7.470</td>\n",
              "      <td>...</td>\n",
              "      <td>146.64</td>\n",
              "      <td>243.456</td>\n",
              "      <td>42</td>\n",
              "      <td>462</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69400</td>\n",
              "      <td>3.070181</td>\n",
              "      <td>69.14</td>\n",
              "      <td>0.531</td>\n",
              "      <td>39912.675</td>\n",
              "      <td>134.6</td>\n",
              "      <td>7.485</td>\n",
              "      <td>7.570</td>\n",
              "      <td>7.495</td>\n",
              "      <td>7.515</td>\n",
              "      <td>...</td>\n",
              "      <td>147.88</td>\n",
              "      <td>924.000</td>\n",
              "      <td>38</td>\n",
              "      <td>458</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>66800</td>\n",
              "      <td>3.074885</td>\n",
              "      <td>59.36</td>\n",
              "      <td>0.542</td>\n",
              "      <td>38873.890</td>\n",
              "      <td>119.3</td>\n",
              "      <td>6.895</td>\n",
              "      <td>7.035</td>\n",
              "      <td>6.920</td>\n",
              "      <td>7.020</td>\n",
              "      <td>...</td>\n",
              "      <td>185.36</td>\n",
              "      <td>225.344</td>\n",
              "      <td>45</td>\n",
              "      <td>472</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>72400</td>\n",
              "      <td>3.108212</td>\n",
              "      <td>59.36</td>\n",
              "      <td>0.542</td>\n",
              "      <td>39701.585</td>\n",
              "      <td>127.7</td>\n",
              "      <td>6.920</td>\n",
              "      <td>7.070</td>\n",
              "      <td>6.815</td>\n",
              "      <td>7.070</td>\n",
              "      <td>...</td>\n",
              "      <td>176.48</td>\n",
              "      <td>225.792</td>\n",
              "      <td>55</td>\n",
              "      <td>395</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ef83f3-26fd-4860-9e2e-d863146d2403')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1ef83f3-26fd-4860-9e2e-d863146d2403 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1ef83f3-26fd-4860-9e2e-d863146d2403');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#delete unnecessary columns\n",
        "del df['3D_available_NO']"
      ],
      "metadata": {
        "id": "NMvTzKDdc1_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df['Genre_Action']"
      ],
      "metadata": {
        "id": "0g5i7kiKdPU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Correlation Analysis"
      ],
      "metadata": {
        "id": "Qyf64jfDjcpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "A2yqiRd6dhRZ",
        "outputId": "e085b90b-f0ed-4d53-d989-336195e364b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Collection  Marketin_expense  Production_expense  \\\n",
              "Collection             1.000000         -0.309711           -0.373947   \n",
              "Marketin_expense      -0.309711          1.000000            0.615376   \n",
              "Production_expense    -0.373947          0.615376            1.000000   \n",
              "Multiplex_coverage     0.303971         -0.707648           -0.747325   \n",
              "Budget                 0.754353         -0.306339           -0.403334   \n",
              "Movie_length          -0.278718          0.533402            0.609577   \n",
              "Lead_ Actor_Rating    -0.110412          0.557617            0.668242   \n",
              "Lead_Actress_rating   -0.109230          0.558538            0.669666   \n",
              "Director_rating       -0.105234          0.557241            0.668155   \n",
              "Producer_rating       -0.112257          0.555388            0.672624   \n",
              "Critic_rating          0.317850         -0.177594           -0.177960   \n",
              "Trailer_views          0.678691         -0.526549           -0.537165   \n",
              "Time_taken             0.140573          0.048600            0.024382   \n",
              "Twitter_hastags        0.052651          0.049715           -0.057913   \n",
              "Avg_age_actors        -0.005188          0.024027            0.028472   \n",
              "Num_multiplex         -0.272365          0.636746            0.691225   \n",
              "Genre_Comedy          -0.036113          0.035203            0.040700   \n",
              "Genre_Drama            0.020424          0.011118            0.016143   \n",
              "Genre_Thriller         0.060124         -0.066084           -0.082437   \n",
              "3D_available_YES       0.192355         -0.120489           -0.086836   \n",
              "\n",
              "                     Multiplex_coverage    Budget  Movie_length  \\\n",
              "Collection                     0.303971  0.754353     -0.278718   \n",
              "Marketin_expense              -0.707648 -0.306339      0.533402   \n",
              "Production_expense            -0.747325 -0.403334      0.609577   \n",
              "Multiplex_coverage             1.000000  0.314842     -0.714380   \n",
              "Budget                         0.314842  1.000000     -0.233983   \n",
              "Movie_length                  -0.714380 -0.233983      1.000000   \n",
              "Lead_ Actor_Rating            -0.749236 -0.169458      0.723420   \n",
              "Lead_Actress_rating           -0.750939 -0.163343      0.724517   \n",
              "Director_rating               -0.748383 -0.162799      0.723945   \n",
              "Producer_rating               -0.749495 -0.165340      0.725696   \n",
              "Critic_rating                  0.066023  0.237713     -0.171255   \n",
              "Trailer_views                  0.524445  0.632985     -0.554295   \n",
              "Time_taken                     0.027185  0.069261     -0.005934   \n",
              "Twitter_hastags                0.016897  0.045096     -0.008140   \n",
              "Avg_age_actors                -0.078364 -0.043350      0.065164   \n",
              "Num_multiplex                 -0.914065 -0.290950      0.655003   \n",
              "Genre_Comedy                  -0.028551 -0.051806      0.075355   \n",
              "Genre_Drama                    0.008637 -0.024516      0.024897   \n",
              "Genre_Thriller                 0.030138  0.055914     -0.096724   \n",
              "3D_available_YES               0.065540  0.167132      0.021640   \n",
              "\n",
              "                     Lead_ Actor_Rating  Lead_Actress_rating  Director_rating  \\\n",
              "Collection                    -0.110412            -0.109230        -0.105234   \n",
              "Marketin_expense               0.557617             0.558538         0.557241   \n",
              "Production_expense             0.668242             0.669666         0.668155   \n",
              "Multiplex_coverage            -0.749236            -0.750939        -0.748383   \n",
              "Budget                        -0.169458            -0.163343        -0.162799   \n",
              "Movie_length                   0.723420             0.724517         0.723945   \n",
              "Lead_ Actor_Rating             1.000000             0.998014         0.997846   \n",
              "Lead_Actress_rating            0.998014             1.000000         0.998222   \n",
              "Director_rating                0.997846             0.998222         1.000000   \n",
              "Producer_rating                0.994594             0.994557         0.994754   \n",
              "Critic_rating                 -0.093442            -0.089485        -0.089439   \n",
              "Trailer_views                 -0.414194            -0.413549        -0.412502   \n",
              "Time_taken                     0.058482             0.057750         0.056154   \n",
              "Twitter_hastags               -0.004881            -0.008653        -0.007326   \n",
              "Avg_age_actors                 0.004379             0.008232         0.009379   \n",
              "Num_multiplex                  0.686076             0.687844         0.686856   \n",
              "Genre_Comedy                   0.014851             0.018377         0.015712   \n",
              "Genre_Drama                   -0.016319            -0.019332        -0.011240   \n",
              "Genre_Thriller                -0.017366            -0.019707        -0.022875   \n",
              "3D_available_YES               0.005008             0.007657         0.008954   \n",
              "\n",
              "                     Producer_rating  Critic_rating  Trailer_views  \\\n",
              "Collection                 -0.112257       0.317850       0.678691   \n",
              "Marketin_expense            0.555388      -0.177594      -0.526549   \n",
              "Production_expense          0.672624      -0.177960      -0.537165   \n",
              "Multiplex_coverage         -0.749495       0.066023       0.524445   \n",
              "Budget                     -0.165340       0.237713       0.632985   \n",
              "Movie_length                0.725696      -0.171255      -0.554295   \n",
              "Lead_ Actor_Rating          0.994594      -0.093442      -0.414194   \n",
              "Lead_Actress_rating         0.994557      -0.089485      -0.413549   \n",
              "Director_rating             0.994754      -0.089439      -0.412502   \n",
              "Producer_rating             1.000000      -0.091957      -0.417957   \n",
              "Critic_rating              -0.091957       1.000000       0.200985   \n",
              "Trailer_views              -0.417957       0.200985       1.000000   \n",
              "Time_taken                  0.047449      -0.011592       0.104337   \n",
              "Twitter_hastags            -0.013669      -0.027859       0.033717   \n",
              "Avg_age_actors              0.005637      -0.010233      -0.004870   \n",
              "Num_multiplex               0.687656      -0.047068      -0.498964   \n",
              "Genre_Comedy                0.023562       0.012654      -0.101046   \n",
              "Genre_Drama                -0.012358       0.034996      -0.025268   \n",
              "Genre_Thriller             -0.023702      -0.039234       0.125530   \n",
              "3D_available_YES            0.013377       0.035370       0.091796   \n",
              "\n",
              "                     Time_taken  Twitter_hastags  Avg_age_actors  \\\n",
              "Collection             0.140573         0.052651       -0.005188   \n",
              "Marketin_expense       0.048600         0.049715        0.024027   \n",
              "Production_expense     0.024382        -0.057913        0.028472   \n",
              "Multiplex_coverage     0.027185         0.016897       -0.078364   \n",
              "Budget                 0.069261         0.045096       -0.043350   \n",
              "Movie_length          -0.005934        -0.008140        0.065164   \n",
              "Lead_ Actor_Rating     0.058482        -0.004881        0.004379   \n",
              "Lead_Actress_rating    0.057750        -0.008653        0.008232   \n",
              "Director_rating        0.056154        -0.007326        0.009379   \n",
              "Producer_rating        0.047449        -0.013669        0.005637   \n",
              "Critic_rating         -0.011592        -0.027859       -0.010233   \n",
              "Trailer_views          0.104337         0.033717       -0.004870   \n",
              "Time_taken             1.000000         0.010841        0.035250   \n",
              "Twitter_hastags        0.010841         1.000000        0.051341   \n",
              "Avg_age_actors         0.035250         0.051341        1.000000   \n",
              "Num_multiplex         -0.056048        -0.002665        0.059602   \n",
              "Genre_Comedy          -0.054714         0.075995       -0.042941   \n",
              "Genre_Drama            0.084872        -0.031783       -0.020145   \n",
              "Genre_Thriller        -0.047950        -0.066465       -0.004067   \n",
              "3D_available_YES      -0.035168        -0.035927       -0.030999   \n",
              "\n",
              "                     Num_multiplex  Genre_Comedy  Genre_Drama  Genre_Thriller  \\\n",
              "Collection               -0.272365     -0.036113     0.020424        0.060124   \n",
              "Marketin_expense          0.636746      0.035203     0.011118       -0.066084   \n",
              "Production_expense        0.691225      0.040700     0.016143       -0.082437   \n",
              "Multiplex_coverage       -0.914065     -0.028551     0.008637        0.030138   \n",
              "Budget                   -0.290950     -0.051806    -0.024516        0.055914   \n",
              "Movie_length              0.655003      0.075355     0.024897       -0.096724   \n",
              "Lead_ Actor_Rating        0.686076      0.014851    -0.016319       -0.017366   \n",
              "Lead_Actress_rating       0.687844      0.018377    -0.019332       -0.019707   \n",
              "Director_rating           0.686856      0.015712    -0.011240       -0.022875   \n",
              "Producer_rating           0.687656      0.023562    -0.012358       -0.023702   \n",
              "Critic_rating            -0.047068      0.012654     0.034996       -0.039234   \n",
              "Trailer_views            -0.498964     -0.101046    -0.025268        0.125530   \n",
              "Time_taken               -0.056048     -0.054714     0.084872       -0.047950   \n",
              "Twitter_hastags          -0.002665      0.075995    -0.031783       -0.066465   \n",
              "Avg_age_actors            0.059602     -0.042941    -0.020145       -0.004067   \n",
              "Num_multiplex             1.000000      0.033252    -0.010194       -0.047379   \n",
              "Genre_Comedy              0.033252      1.000000    -0.320091       -0.494670   \n",
              "Genre_Drama              -0.010194     -0.320091     1.000000       -0.392406   \n",
              "Genre_Thriller           -0.047379     -0.494670    -0.392406        1.000000   \n",
              "3D_available_YES         -0.049067      0.054472     0.005348        0.001826   \n",
              "\n",
              "                     3D_available_YES  \n",
              "Collection                   0.192355  \n",
              "Marketin_expense            -0.120489  \n",
              "Production_expense          -0.086836  \n",
              "Multiplex_coverage           0.065540  \n",
              "Budget                       0.167132  \n",
              "Movie_length                 0.021640  \n",
              "Lead_ Actor_Rating           0.005008  \n",
              "Lead_Actress_rating          0.007657  \n",
              "Director_rating              0.008954  \n",
              "Producer_rating              0.013377  \n",
              "Critic_rating                0.035370  \n",
              "Trailer_views                0.091796  \n",
              "Time_taken                  -0.035168  \n",
              "Twitter_hastags             -0.035927  \n",
              "Avg_age_actors              -0.030999  \n",
              "Num_multiplex               -0.049067  \n",
              "Genre_Comedy                 0.054472  \n",
              "Genre_Drama                  0.005348  \n",
              "Genre_Thriller               0.001826  \n",
              "3D_available_YES             1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f1a5ea52-d9d8-47bd-ae3a-945dfe945852\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Collection</th>\n",
              "      <th>Marketin_expense</th>\n",
              "      <th>Production_expense</th>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Movie_length</th>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <th>Director_rating</th>\n",
              "      <th>Producer_rating</th>\n",
              "      <th>Critic_rating</th>\n",
              "      <th>Trailer_views</th>\n",
              "      <th>Time_taken</th>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <th>Num_multiplex</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Thriller</th>\n",
              "      <th>3D_available_YES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Collection</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.309711</td>\n",
              "      <td>-0.373947</td>\n",
              "      <td>0.303971</td>\n",
              "      <td>0.754353</td>\n",
              "      <td>-0.278718</td>\n",
              "      <td>-0.110412</td>\n",
              "      <td>-0.109230</td>\n",
              "      <td>-0.105234</td>\n",
              "      <td>-0.112257</td>\n",
              "      <td>0.317850</td>\n",
              "      <td>0.678691</td>\n",
              "      <td>0.140573</td>\n",
              "      <td>0.052651</td>\n",
              "      <td>-0.005188</td>\n",
              "      <td>-0.272365</td>\n",
              "      <td>-0.036113</td>\n",
              "      <td>0.020424</td>\n",
              "      <td>0.060124</td>\n",
              "      <td>0.192355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Marketin_expense</th>\n",
              "      <td>-0.309711</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.615376</td>\n",
              "      <td>-0.707648</td>\n",
              "      <td>-0.306339</td>\n",
              "      <td>0.533402</td>\n",
              "      <td>0.557617</td>\n",
              "      <td>0.558538</td>\n",
              "      <td>0.557241</td>\n",
              "      <td>0.555388</td>\n",
              "      <td>-0.177594</td>\n",
              "      <td>-0.526549</td>\n",
              "      <td>0.048600</td>\n",
              "      <td>0.049715</td>\n",
              "      <td>0.024027</td>\n",
              "      <td>0.636746</td>\n",
              "      <td>0.035203</td>\n",
              "      <td>0.011118</td>\n",
              "      <td>-0.066084</td>\n",
              "      <td>-0.120489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Production_expense</th>\n",
              "      <td>-0.373947</td>\n",
              "      <td>0.615376</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.747325</td>\n",
              "      <td>-0.403334</td>\n",
              "      <td>0.609577</td>\n",
              "      <td>0.668242</td>\n",
              "      <td>0.669666</td>\n",
              "      <td>0.668155</td>\n",
              "      <td>0.672624</td>\n",
              "      <td>-0.177960</td>\n",
              "      <td>-0.537165</td>\n",
              "      <td>0.024382</td>\n",
              "      <td>-0.057913</td>\n",
              "      <td>0.028472</td>\n",
              "      <td>0.691225</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>0.016143</td>\n",
              "      <td>-0.082437</td>\n",
              "      <td>-0.086836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <td>0.303971</td>\n",
              "      <td>-0.707648</td>\n",
              "      <td>-0.747325</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.314842</td>\n",
              "      <td>-0.714380</td>\n",
              "      <td>-0.749236</td>\n",
              "      <td>-0.750939</td>\n",
              "      <td>-0.748383</td>\n",
              "      <td>-0.749495</td>\n",
              "      <td>0.066023</td>\n",
              "      <td>0.524445</td>\n",
              "      <td>0.027185</td>\n",
              "      <td>0.016897</td>\n",
              "      <td>-0.078364</td>\n",
              "      <td>-0.914065</td>\n",
              "      <td>-0.028551</td>\n",
              "      <td>0.008637</td>\n",
              "      <td>0.030138</td>\n",
              "      <td>0.065540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Budget</th>\n",
              "      <td>0.754353</td>\n",
              "      <td>-0.306339</td>\n",
              "      <td>-0.403334</td>\n",
              "      <td>0.314842</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>-0.169458</td>\n",
              "      <td>-0.163343</td>\n",
              "      <td>-0.162799</td>\n",
              "      <td>-0.165340</td>\n",
              "      <td>0.237713</td>\n",
              "      <td>0.632985</td>\n",
              "      <td>0.069261</td>\n",
              "      <td>0.045096</td>\n",
              "      <td>-0.043350</td>\n",
              "      <td>-0.290950</td>\n",
              "      <td>-0.051806</td>\n",
              "      <td>-0.024516</td>\n",
              "      <td>0.055914</td>\n",
              "      <td>0.167132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Movie_length</th>\n",
              "      <td>-0.278718</td>\n",
              "      <td>0.533402</td>\n",
              "      <td>0.609577</td>\n",
              "      <td>-0.714380</td>\n",
              "      <td>-0.233983</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.723420</td>\n",
              "      <td>0.724517</td>\n",
              "      <td>0.723945</td>\n",
              "      <td>0.725696</td>\n",
              "      <td>-0.171255</td>\n",
              "      <td>-0.554295</td>\n",
              "      <td>-0.005934</td>\n",
              "      <td>-0.008140</td>\n",
              "      <td>0.065164</td>\n",
              "      <td>0.655003</td>\n",
              "      <td>0.075355</td>\n",
              "      <td>0.024897</td>\n",
              "      <td>-0.096724</td>\n",
              "      <td>0.021640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <td>-0.110412</td>\n",
              "      <td>0.557617</td>\n",
              "      <td>0.668242</td>\n",
              "      <td>-0.749236</td>\n",
              "      <td>-0.169458</td>\n",
              "      <td>0.723420</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998014</td>\n",
              "      <td>0.997846</td>\n",
              "      <td>0.994594</td>\n",
              "      <td>-0.093442</td>\n",
              "      <td>-0.414194</td>\n",
              "      <td>0.058482</td>\n",
              "      <td>-0.004881</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.686076</td>\n",
              "      <td>0.014851</td>\n",
              "      <td>-0.016319</td>\n",
              "      <td>-0.017366</td>\n",
              "      <td>0.005008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <td>-0.109230</td>\n",
              "      <td>0.558538</td>\n",
              "      <td>0.669666</td>\n",
              "      <td>-0.750939</td>\n",
              "      <td>-0.163343</td>\n",
              "      <td>0.724517</td>\n",
              "      <td>0.998014</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998222</td>\n",
              "      <td>0.994557</td>\n",
              "      <td>-0.089485</td>\n",
              "      <td>-0.413549</td>\n",
              "      <td>0.057750</td>\n",
              "      <td>-0.008653</td>\n",
              "      <td>0.008232</td>\n",
              "      <td>0.687844</td>\n",
              "      <td>0.018377</td>\n",
              "      <td>-0.019332</td>\n",
              "      <td>-0.019707</td>\n",
              "      <td>0.007657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Director_rating</th>\n",
              "      <td>-0.105234</td>\n",
              "      <td>0.557241</td>\n",
              "      <td>0.668155</td>\n",
              "      <td>-0.748383</td>\n",
              "      <td>-0.162799</td>\n",
              "      <td>0.723945</td>\n",
              "      <td>0.997846</td>\n",
              "      <td>0.998222</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994754</td>\n",
              "      <td>-0.089439</td>\n",
              "      <td>-0.412502</td>\n",
              "      <td>0.056154</td>\n",
              "      <td>-0.007326</td>\n",
              "      <td>0.009379</td>\n",
              "      <td>0.686856</td>\n",
              "      <td>0.015712</td>\n",
              "      <td>-0.011240</td>\n",
              "      <td>-0.022875</td>\n",
              "      <td>0.008954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Producer_rating</th>\n",
              "      <td>-0.112257</td>\n",
              "      <td>0.555388</td>\n",
              "      <td>0.672624</td>\n",
              "      <td>-0.749495</td>\n",
              "      <td>-0.165340</td>\n",
              "      <td>0.725696</td>\n",
              "      <td>0.994594</td>\n",
              "      <td>0.994557</td>\n",
              "      <td>0.994754</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.091957</td>\n",
              "      <td>-0.417957</td>\n",
              "      <td>0.047449</td>\n",
              "      <td>-0.013669</td>\n",
              "      <td>0.005637</td>\n",
              "      <td>0.687656</td>\n",
              "      <td>0.023562</td>\n",
              "      <td>-0.012358</td>\n",
              "      <td>-0.023702</td>\n",
              "      <td>0.013377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Critic_rating</th>\n",
              "      <td>0.317850</td>\n",
              "      <td>-0.177594</td>\n",
              "      <td>-0.177960</td>\n",
              "      <td>0.066023</td>\n",
              "      <td>0.237713</td>\n",
              "      <td>-0.171255</td>\n",
              "      <td>-0.093442</td>\n",
              "      <td>-0.089485</td>\n",
              "      <td>-0.089439</td>\n",
              "      <td>-0.091957</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200985</td>\n",
              "      <td>-0.011592</td>\n",
              "      <td>-0.027859</td>\n",
              "      <td>-0.010233</td>\n",
              "      <td>-0.047068</td>\n",
              "      <td>0.012654</td>\n",
              "      <td>0.034996</td>\n",
              "      <td>-0.039234</td>\n",
              "      <td>0.035370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trailer_views</th>\n",
              "      <td>0.678691</td>\n",
              "      <td>-0.526549</td>\n",
              "      <td>-0.537165</td>\n",
              "      <td>0.524445</td>\n",
              "      <td>0.632985</td>\n",
              "      <td>-0.554295</td>\n",
              "      <td>-0.414194</td>\n",
              "      <td>-0.413549</td>\n",
              "      <td>-0.412502</td>\n",
              "      <td>-0.417957</td>\n",
              "      <td>0.200985</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.104337</td>\n",
              "      <td>0.033717</td>\n",
              "      <td>-0.004870</td>\n",
              "      <td>-0.498964</td>\n",
              "      <td>-0.101046</td>\n",
              "      <td>-0.025268</td>\n",
              "      <td>0.125530</td>\n",
              "      <td>0.091796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time_taken</th>\n",
              "      <td>0.140573</td>\n",
              "      <td>0.048600</td>\n",
              "      <td>0.024382</td>\n",
              "      <td>0.027185</td>\n",
              "      <td>0.069261</td>\n",
              "      <td>-0.005934</td>\n",
              "      <td>0.058482</td>\n",
              "      <td>0.057750</td>\n",
              "      <td>0.056154</td>\n",
              "      <td>0.047449</td>\n",
              "      <td>-0.011592</td>\n",
              "      <td>0.104337</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.010841</td>\n",
              "      <td>0.035250</td>\n",
              "      <td>-0.056048</td>\n",
              "      <td>-0.054714</td>\n",
              "      <td>0.084872</td>\n",
              "      <td>-0.047950</td>\n",
              "      <td>-0.035168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <td>0.052651</td>\n",
              "      <td>0.049715</td>\n",
              "      <td>-0.057913</td>\n",
              "      <td>0.016897</td>\n",
              "      <td>0.045096</td>\n",
              "      <td>-0.008140</td>\n",
              "      <td>-0.004881</td>\n",
              "      <td>-0.008653</td>\n",
              "      <td>-0.007326</td>\n",
              "      <td>-0.013669</td>\n",
              "      <td>-0.027859</td>\n",
              "      <td>0.033717</td>\n",
              "      <td>0.010841</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.051341</td>\n",
              "      <td>-0.002665</td>\n",
              "      <td>0.075995</td>\n",
              "      <td>-0.031783</td>\n",
              "      <td>-0.066465</td>\n",
              "      <td>-0.035927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <td>-0.005188</td>\n",
              "      <td>0.024027</td>\n",
              "      <td>0.028472</td>\n",
              "      <td>-0.078364</td>\n",
              "      <td>-0.043350</td>\n",
              "      <td>0.065164</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.008232</td>\n",
              "      <td>0.009379</td>\n",
              "      <td>0.005637</td>\n",
              "      <td>-0.010233</td>\n",
              "      <td>-0.004870</td>\n",
              "      <td>0.035250</td>\n",
              "      <td>0.051341</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.059602</td>\n",
              "      <td>-0.042941</td>\n",
              "      <td>-0.020145</td>\n",
              "      <td>-0.004067</td>\n",
              "      <td>-0.030999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Num_multiplex</th>\n",
              "      <td>-0.272365</td>\n",
              "      <td>0.636746</td>\n",
              "      <td>0.691225</td>\n",
              "      <td>-0.914065</td>\n",
              "      <td>-0.290950</td>\n",
              "      <td>0.655003</td>\n",
              "      <td>0.686076</td>\n",
              "      <td>0.687844</td>\n",
              "      <td>0.686856</td>\n",
              "      <td>0.687656</td>\n",
              "      <td>-0.047068</td>\n",
              "      <td>-0.498964</td>\n",
              "      <td>-0.056048</td>\n",
              "      <td>-0.002665</td>\n",
              "      <td>0.059602</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.033252</td>\n",
              "      <td>-0.010194</td>\n",
              "      <td>-0.047379</td>\n",
              "      <td>-0.049067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <td>-0.036113</td>\n",
              "      <td>0.035203</td>\n",
              "      <td>0.040700</td>\n",
              "      <td>-0.028551</td>\n",
              "      <td>-0.051806</td>\n",
              "      <td>0.075355</td>\n",
              "      <td>0.014851</td>\n",
              "      <td>0.018377</td>\n",
              "      <td>0.015712</td>\n",
              "      <td>0.023562</td>\n",
              "      <td>0.012654</td>\n",
              "      <td>-0.101046</td>\n",
              "      <td>-0.054714</td>\n",
              "      <td>0.075995</td>\n",
              "      <td>-0.042941</td>\n",
              "      <td>0.033252</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.320091</td>\n",
              "      <td>-0.494670</td>\n",
              "      <td>0.054472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Genre_Drama</th>\n",
              "      <td>0.020424</td>\n",
              "      <td>0.011118</td>\n",
              "      <td>0.016143</td>\n",
              "      <td>0.008637</td>\n",
              "      <td>-0.024516</td>\n",
              "      <td>0.024897</td>\n",
              "      <td>-0.016319</td>\n",
              "      <td>-0.019332</td>\n",
              "      <td>-0.011240</td>\n",
              "      <td>-0.012358</td>\n",
              "      <td>0.034996</td>\n",
              "      <td>-0.025268</td>\n",
              "      <td>0.084872</td>\n",
              "      <td>-0.031783</td>\n",
              "      <td>-0.020145</td>\n",
              "      <td>-0.010194</td>\n",
              "      <td>-0.320091</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.392406</td>\n",
              "      <td>0.005348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Genre_Thriller</th>\n",
              "      <td>0.060124</td>\n",
              "      <td>-0.066084</td>\n",
              "      <td>-0.082437</td>\n",
              "      <td>0.030138</td>\n",
              "      <td>0.055914</td>\n",
              "      <td>-0.096724</td>\n",
              "      <td>-0.017366</td>\n",
              "      <td>-0.019707</td>\n",
              "      <td>-0.022875</td>\n",
              "      <td>-0.023702</td>\n",
              "      <td>-0.039234</td>\n",
              "      <td>0.125530</td>\n",
              "      <td>-0.047950</td>\n",
              "      <td>-0.066465</td>\n",
              "      <td>-0.004067</td>\n",
              "      <td>-0.047379</td>\n",
              "      <td>-0.494670</td>\n",
              "      <td>-0.392406</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.001826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3D_available_YES</th>\n",
              "      <td>0.192355</td>\n",
              "      <td>-0.120489</td>\n",
              "      <td>-0.086836</td>\n",
              "      <td>0.065540</td>\n",
              "      <td>0.167132</td>\n",
              "      <td>0.021640</td>\n",
              "      <td>0.005008</td>\n",
              "      <td>0.007657</td>\n",
              "      <td>0.008954</td>\n",
              "      <td>0.013377</td>\n",
              "      <td>0.035370</td>\n",
              "      <td>0.091796</td>\n",
              "      <td>-0.035168</td>\n",
              "      <td>-0.035927</td>\n",
              "      <td>-0.030999</td>\n",
              "      <td>-0.049067</td>\n",
              "      <td>0.054472</td>\n",
              "      <td>0.005348</td>\n",
              "      <td>0.001826</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f1a5ea52-d9d8-47bd-ae3a-945dfe945852')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f1a5ea52-d9d8-47bd-ae3a-945dfe945852 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f1a5ea52-d9d8-47bd-ae3a-945dfe945852');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from the correlation analysis, we can see that the feature which is atmost correlated with the 'collection'(target) is 'Budget'."
      ],
      "metadata": {
        "id": "eazTTlkWji1O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Simple Linear regression"
      ],
      "metadata": {
        "id": "1WOZRJLdkDDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "lr=LinearRegression()\n",
        "y=df['Collection']\n",
        "x=df[['Budget']]\n",
        "lr.fit(x,y)\n",
        "regression_line=lr.predict(x)\n",
        "print(lr.intercept_,lr.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_rAS1vKTLRj",
        "outputId": "7e02ae49-892f-4a1d-aedb-1f7931355472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-70624.10545910442 [3.388584]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(x,regression_line,color='red',linewidth=4)\n",
        "plt.xlabel('Budget')\n",
        "plt.ylabel('collection')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "BrfGB_qNUGm9",
        "outputId": "0edefb6d-ae42-4959-c626-52fd1a0becf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'collection')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multiple Linear Regression"
      ],
      "metadata": {
        "id": "JW_kBnCbm9ao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_multi=df.drop(\"Collection\",axis=1)\n",
        "x_multi.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "nXX83OwSVds6",
        "outputId": "096a2f58-9d89-4b3c-b4b7-506596373a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Marketin_expense  Production_expense  Multiplex_coverage     Budget  \\\n",
              "0          3.050523               59.62               0.462  36524.125   \n",
              "1          3.070199               69.14               0.531  35668.655   \n",
              "2          3.070181               69.14               0.531  39912.675   \n",
              "3          3.074885               59.36               0.542  38873.890   \n",
              "4          3.108212               59.36               0.542  39701.585   \n",
              "\n",
              "   Movie_length  Lead_ Actor_Rating  Lead_Actress_rating  Director_rating  \\\n",
              "0         138.7               7.825                8.095            7.910   \n",
              "1         152.4               7.505                7.650            7.440   \n",
              "2         134.6               7.485                7.570            7.495   \n",
              "3         119.3               6.895                7.035            6.920   \n",
              "4         127.7               6.920                7.070            6.815   \n",
              "\n",
              "   Producer_rating  Critic_rating  Trailer_views  Time_taken  Twitter_hastags  \\\n",
              "0            7.995           7.94         527367      109.60          223.840   \n",
              "1            7.470           7.44         494055      146.64          243.456   \n",
              "2            7.515           7.44         547051      147.88          924.000   \n",
              "3            7.020           8.26         516279      185.36          225.344   \n",
              "4            7.070           8.26         531448      176.48          225.792   \n",
              "\n",
              "   Avg_age_actors  Num_multiplex  Genre_Comedy  Genre_Drama  Genre_Thriller  \\\n",
              "0              23            494             0            0               1   \n",
              "1              42            462             0            1               0   \n",
              "2              38            458             1            0               0   \n",
              "3              45            472             0            1               0   \n",
              "4              55            395             0            1               0   \n",
              "\n",
              "   3D_available_YES  \n",
              "0                 1  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 1  \n",
              "4                 0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a53eca2-7d2e-44db-8c9e-b0f3318b6249\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marketin_expense</th>\n",
              "      <th>Production_expense</th>\n",
              "      <th>Multiplex_coverage</th>\n",
              "      <th>Budget</th>\n",
              "      <th>Movie_length</th>\n",
              "      <th>Lead_ Actor_Rating</th>\n",
              "      <th>Lead_Actress_rating</th>\n",
              "      <th>Director_rating</th>\n",
              "      <th>Producer_rating</th>\n",
              "      <th>Critic_rating</th>\n",
              "      <th>Trailer_views</th>\n",
              "      <th>Time_taken</th>\n",
              "      <th>Twitter_hastags</th>\n",
              "      <th>Avg_age_actors</th>\n",
              "      <th>Num_multiplex</th>\n",
              "      <th>Genre_Comedy</th>\n",
              "      <th>Genre_Drama</th>\n",
              "      <th>Genre_Thriller</th>\n",
              "      <th>3D_available_YES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.050523</td>\n",
              "      <td>59.62</td>\n",
              "      <td>0.462</td>\n",
              "      <td>36524.125</td>\n",
              "      <td>138.7</td>\n",
              "      <td>7.825</td>\n",
              "      <td>8.095</td>\n",
              "      <td>7.910</td>\n",
              "      <td>7.995</td>\n",
              "      <td>7.94</td>\n",
              "      <td>527367</td>\n",
              "      <td>109.60</td>\n",
              "      <td>223.840</td>\n",
              "      <td>23</td>\n",
              "      <td>494</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.070199</td>\n",
              "      <td>69.14</td>\n",
              "      <td>0.531</td>\n",
              "      <td>35668.655</td>\n",
              "      <td>152.4</td>\n",
              "      <td>7.505</td>\n",
              "      <td>7.650</td>\n",
              "      <td>7.440</td>\n",
              "      <td>7.470</td>\n",
              "      <td>7.44</td>\n",
              "      <td>494055</td>\n",
              "      <td>146.64</td>\n",
              "      <td>243.456</td>\n",
              "      <td>42</td>\n",
              "      <td>462</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.070181</td>\n",
              "      <td>69.14</td>\n",
              "      <td>0.531</td>\n",
              "      <td>39912.675</td>\n",
              "      <td>134.6</td>\n",
              "      <td>7.485</td>\n",
              "      <td>7.570</td>\n",
              "      <td>7.495</td>\n",
              "      <td>7.515</td>\n",
              "      <td>7.44</td>\n",
              "      <td>547051</td>\n",
              "      <td>147.88</td>\n",
              "      <td>924.000</td>\n",
              "      <td>38</td>\n",
              "      <td>458</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.074885</td>\n",
              "      <td>59.36</td>\n",
              "      <td>0.542</td>\n",
              "      <td>38873.890</td>\n",
              "      <td>119.3</td>\n",
              "      <td>6.895</td>\n",
              "      <td>7.035</td>\n",
              "      <td>6.920</td>\n",
              "      <td>7.020</td>\n",
              "      <td>8.26</td>\n",
              "      <td>516279</td>\n",
              "      <td>185.36</td>\n",
              "      <td>225.344</td>\n",
              "      <td>45</td>\n",
              "      <td>472</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.108212</td>\n",
              "      <td>59.36</td>\n",
              "      <td>0.542</td>\n",
              "      <td>39701.585</td>\n",
              "      <td>127.7</td>\n",
              "      <td>6.920</td>\n",
              "      <td>7.070</td>\n",
              "      <td>6.815</td>\n",
              "      <td>7.070</td>\n",
              "      <td>8.26</td>\n",
              "      <td>531448</td>\n",
              "      <td>176.48</td>\n",
              "      <td>225.792</td>\n",
              "      <td>55</td>\n",
              "      <td>395</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a53eca2-7d2e-44db-8c9e-b0f3318b6249')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a53eca2-7d2e-44db-8c9e-b0f3318b6249 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a53eca2-7d2e-44db-8c9e-b0f3318b6249');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_multi=df['Collection']"
      ],
      "metadata": {
        "id": "n72anFpxZ6tW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model taining without splitting\n",
        "lr.fit(x_multi,y_multi)\n",
        "print(lr.intercept_,lr.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6Ll8Pb3aWv2",
        "outputId": "b662c9b7-ce6c-4791-8eb7-b0930a18d028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-159361.76886924737 [ 9.66671082e+02 -6.25478537e+01  2.65168392e+04  2.15738234e+00\n",
            " -3.60671093e+01  8.53583151e+03 -1.40727631e+04  1.21806614e+04\n",
            " -2.63253967e+03  3.67503970e+03  1.00653022e-01  3.40347440e+01\n",
            "  5.55368261e+00  5.09699981e+01  1.56458024e+01  4.17396939e+03\n",
            "  4.47170229e+03  3.20132381e+03  2.47259466e+03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the datainto train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_multi,y_multi,test_size=0.2,random_state=0)"
      ],
      "metadata": {
        "id": "59Q3-ts4a1Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model training and prediction for test data\n",
        "lr.fit(x_train,y_train)\n",
        "y_pred_test=lr.predict(x_test)\n",
        "y_pred_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l2fe15Gc4tx",
        "outputId": "37d71304-6de6-443a-d921-98bcfdea627d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([45488.53544783, 54358.27864328, 67145.76839519, 62049.59116147,\n",
              "       38457.69377522, 31682.95458895, 49841.28055941, 74948.46422632,\n",
              "       10671.57552665, 23480.3775603 , 44332.22143222, 29666.04230181,\n",
              "       51504.70956988, 54463.76135676, 36708.58392172, 33673.12805413,\n",
              "       48859.26214456, 27480.75340518, 45188.83051011, 62087.90804133,\n",
              "       53833.26983156, 81817.99161128, 38300.70384266, 60410.17265884,\n",
              "       59743.50022123, 54331.43601473, 49476.51896328, 44485.88069553,\n",
              "       39811.87249076, 48334.38418292, 44698.26207927, 69098.39070335,\n",
              "       46925.82034464, 83286.15091819, 57971.48545952, 46934.94055094,\n",
              "       64750.23530748, 57584.40230335, 68773.26005041, 16511.05594827,\n",
              "       53894.89981711, 48120.44626486, 46438.13453717, 51498.10693162,\n",
              "       34908.4104853 , 32088.97185921, -4849.27043985, 35576.97397823,\n",
              "       51025.05636312, 78458.12562106, 40910.34310117, 16190.38289093,\n",
              "       45628.69350475, 48047.98818485, 77287.1225122 , 51778.0959102 ,\n",
              "       57303.04220641, 35912.71287506, 37182.22902129, 42202.26213704,\n",
              "       44527.1448397 , 55677.9124057 , 65748.51987116, 32461.59098058,\n",
              "       53808.65872169, 50396.05707858, 31098.52069279, 51009.85134364,\n",
              "       46601.95467898, 31177.42081495, 37469.99901127, 72621.67075029,\n",
              "       42404.48783908, 26366.03986558, 42078.69628949, 50577.00325088,\n",
              "       45772.96165894, 68085.68845915, 46972.44996106, 52696.58519309])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction for train data\n",
        "y_pred_train=lr.predict(x_train)\n",
        "y_pred_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdCKOFAReKZa",
        "outputId": "d9fe4086-09b8-45e4-ef2f-4b63e4b8cb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([40296.01271681, 44337.12892651, 63647.30192003, 36794.84163897,\n",
              "       60179.7868317 , 69965.72163254, 40647.56994219, 10418.61077973,\n",
              "       41109.15120581, 57743.28737796, 47938.98954779, 71613.82714599,\n",
              "       51815.58966197, 19524.29933954, 64352.07780736, 31643.21375147,\n",
              "       41673.54233256, 32697.6726407 , 70787.79124059, 76128.29070433,\n",
              "       49724.65244586, 43663.51715063, 43854.00547862, 59012.11353287,\n",
              "       85846.62103092, 42466.33352658, 52986.79051695, 51069.50100756,\n",
              "       36306.12121173, 61510.94102082, 53218.4215364 , 66777.37054086,\n",
              "       47060.27319791, 43485.55057096, 28593.76495149, 37723.8697197 ,\n",
              "       60981.13042758, 27986.64185833, 58454.3663669 , 50816.73703949,\n",
              "       57916.97940886, 56519.66726665, 64014.25240833, 80980.61724596,\n",
              "       41768.08179315, 28244.17374044, 33601.3064228 , 50656.43297331,\n",
              "       50461.00330098, 50334.16889198, 41541.55574075, 47254.85312481,\n",
              "       42385.9074938 , 57400.18185569, 42819.1086024 , 58328.59339747,\n",
              "       53366.08981949, 63505.71283441, 48781.73580501, 35915.85394833,\n",
              "       56087.73171033, 75177.56837757, 25269.03059104, 46840.56470858,\n",
              "       62858.85341277, 46284.6630058 , 38242.49474149, 29877.89027147,\n",
              "       54508.87910418, 44116.39472676, 43243.91988937, 40029.79494073,\n",
              "       53598.43559499, 32479.71273914, 46934.55933031, 32588.66579268,\n",
              "       65779.9713806 , 27235.55593042, 67038.99523534, 62896.66516073,\n",
              "       69058.77387678, 40565.70228216, 36507.71902846, 41043.20817437,\n",
              "       75781.81355521, 32762.22046452, 67457.39585599, 78630.34471681,\n",
              "       60733.61364416, 31536.76651645, 46544.93823102, 71573.97483765,\n",
              "       57979.88371011, 43775.02310178, 49330.75958126, 54532.56066561,\n",
              "       49840.15263797, 44975.37434802, 57486.68408903, 38477.02364143,\n",
              "       89402.35202699, 54234.7181923 , 47479.77758898, 36127.08840485,\n",
              "       61458.24750691, 41096.18127279, 46967.00000732, 53024.34138131,\n",
              "       46419.23085269, 49474.42501302, 49972.69787281, 49607.01720519,\n",
              "       40668.66532728, 35637.23413959, 72294.38233501, 49441.73627818,\n",
              "       32604.2663275 , 41468.84346996, 45531.78627398, 41685.88640366,\n",
              "       29899.06549298, 53019.64898771, 50672.19339665, 62512.30056934,\n",
              "       59389.3928435 , 63291.6814904 , 49949.73173896, 46521.8364547 ,\n",
              "       77103.15320792, 14310.60495119, 47116.59851252, 35216.22706258,\n",
              "       47217.3942881 , 48220.62873862, 40677.52696827, 31092.47053489,\n",
              "       54597.5505031 , 60105.53486218, 80408.04449448, 22287.2383199 ,\n",
              "       28040.60530253, 51785.63942462, 68693.41659352, 34498.94473221,\n",
              "       52156.78861987, 40996.2832104 , 57243.39353005, 37852.98176401,\n",
              "       46858.33236282, 41277.58921616, 26383.57094104, 48639.20842789,\n",
              "        9621.38834229,  7492.61473269, 84351.69947946, 65203.48045128,\n",
              "       38615.99196613, 74918.67007858, 45825.51601571, 69036.31403395,\n",
              "       31349.92790976, 39270.23248561, 45120.57885994, 67378.80443067,\n",
              "       36884.60624686, 58754.18958537, 42199.96922457, 29744.2548982 ,\n",
              "       71218.60048678, 38266.34009842, 51286.5822251 , 41939.13715493,\n",
              "       46531.56627972, 46400.8543773 , 44385.00117074, 45923.34824991,\n",
              "       43176.52743117, 44413.87831759, 70768.30980019, 43015.14753359,\n",
              "       49879.13828726, 58294.56602458, 37922.64242486, 76599.41512619,\n",
              "       67266.06438015, 66588.58506123, 60457.70321344, 42443.82179989,\n",
              "       48327.43207688, 46156.29174583, 54269.11896162, 33500.30855887,\n",
              "       33092.50986024, 74137.1602352 , 34947.36814304, 62101.26312156,\n",
              "       69428.36208304, 40051.42476574, 56815.59952052, 41619.45066318,\n",
              "       60060.58372333, 47635.48483303, 30283.82728765, 36991.11714764,\n",
              "       52767.0508465 , 38831.22171325, 28372.652671  , 27418.48955385,\n",
              "       37599.86094689, 31863.24676558, 42338.22889901, 33883.89209858,\n",
              "       56559.2125105 , 47572.32778411, 51950.84452123, 47451.60417318,\n",
              "       60102.77657616, 32182.50430025, 50685.01993292, 56215.43104316,\n",
              "       50742.73939991, 37588.79172447, 77122.21609818, 10456.01835904,\n",
              "       57588.65340464, 65326.03040406, 45004.28365441, 64459.41654165,\n",
              "       57487.44002625, 43714.17620021, 44066.20278057, 45748.97644203,\n",
              "       46645.8167382 , 13375.47013239, 33657.58596607, 66500.87833673,\n",
              "       63123.12938248, 24312.5110594 , 25453.84398557, 71728.05671031,\n",
              "       39975.04833093, 51305.27581253, 16532.72879613, 82321.72039002,\n",
              "       52614.73828008, 77502.37208168, 43478.0355201 , 44323.01815679,\n",
              "       41037.83267547, 34710.25666025, 51602.98342346, 49658.75658591,\n",
              "       88152.69185695, 46954.32919438, 70522.96311179, 61660.73690354,\n",
              "       52472.72305573, 94469.78242376, 36499.19983978, 51080.66054386,\n",
              "       43703.07142082, 48023.15849807, 71533.17878962, 48877.26122623,\n",
              "       44861.30932936, 49671.13888432, 50513.19058831, 48857.5778953 ,\n",
              "       66807.38191913, 48409.54365655, 64328.30158081, 92396.86581688,\n",
              "       36656.33364757, 31624.39614794, 74741.76129472, 36574.30055723,\n",
              "       24233.24086998, 29279.03306374, 49637.06469705, 50372.10300021,\n",
              "       40535.37673032, 34880.87869255, 13631.23256985, 57343.81108731,\n",
              "       66478.71058868, 59877.05154308, 65069.20461343, 46451.25284643,\n",
              "       42398.11964448, 55812.19785914, 56851.54804409, 37104.9576238 ,\n",
              "       47908.92665077, 38878.44820401, 52441.51477845, 35018.38742911,\n",
              "       49417.25920967, 41696.34287815,  4813.13511441, 50756.83598393,\n",
              "       10805.54987196, 65075.76401798, 53307.67510328, 55244.94866428,\n",
              "       63794.35781942, 51119.26885006, 56121.86172262, 59826.46757957,\n",
              "       49953.50898721, 54633.04243858, 19570.52384162, 38199.39106414,\n",
              "       39344.16641561, 81227.53050991, 58784.95629607, 39148.65816953,\n",
              "       65560.81167802, 43413.71782734, 33021.1448313 , 39080.58172074])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy of the model using r square method\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score(y_test,y_pred_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn3LmAmcdX0z",
        "outputId": "f6af469f-ccdb-4fb3-8535-4bdc8f8a6473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6294584067165659"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train,y_pred_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqze4b2AdoXH",
        "outputId": "dfd3bdfd-babd-4fed-878a-f7ca38e111e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7032392467424771"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Linear models other than OLS (Ordinary least squares)"
      ],
      "metadata": {
        "id": "pxx9rdHhofuz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Standardization of data"
      ],
      "metadata": {
        "id": "gxQLNAEGpOwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "x_train_s=sc.fit_transform(x_train)\n",
        "x_test_s=sc.fit_transform(x_test)"
      ],
      "metadata": {
        "id": "7ZXlNeAweftd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Shrinkage methods:\n",
        "###1.Ridge"
      ],
      "metadata": {
        "id": "BNsEmapzpVzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "rd=Ridge(alpha=0.5)\n",
        "rd.fit(x_train_s,y_train)\n",
        "y_pred_s=rd.predict(x_test_s)\n",
        "y_pred_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Olj_Ng8ulTe3",
        "outputId": "3bcb8f59-c1ee-4326-feb6-c952530aba98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([46476.89368336, 55171.44958513, 68087.95396647, 64294.11329753,\n",
              "       40618.54867448, 33251.8886704 , 50549.05425177, 75145.16479465,\n",
              "       12807.82863039, 23948.81988917, 45190.76696496, 30322.32651643,\n",
              "       52191.08070669, 55742.59519036, 37730.5987516 , 35906.81790053,\n",
              "       50344.33798305, 29424.36817545, 46665.25568393, 63755.90684701,\n",
              "       55406.00847628, 83689.58725283, 39578.11081731, 62938.66728494,\n",
              "       60032.10593604, 55427.80627091, 51305.50242923, 45862.74022745,\n",
              "       41596.32088238, 49451.3879843 , 45248.14765387, 70063.64171512,\n",
              "       48268.73702111, 86373.22901507, 58993.10429251, 48673.09171808,\n",
              "       65187.90776484, 58284.06105986, 70529.05171182, 19643.46676431,\n",
              "       56562.84162096, 49545.03652992, 47329.11468561, 52716.80411284,\n",
              "       35395.93415325, 34300.35633012, -3512.31754669, 37010.40735489,\n",
              "       52080.90609385, 80437.6380752 , 42914.95048787, 17199.02314522,\n",
              "       46029.94760216, 48646.3606515 , 78093.32768666, 51837.80027793,\n",
              "       59263.61785434, 37535.16625031, 38821.83419345, 42850.79068548,\n",
              "       47201.49128987, 57713.44131744, 67671.60335295, 34010.12918811,\n",
              "       55458.11678033, 51668.42466188, 33011.45383581, 52651.69460268,\n",
              "       46925.77634934, 31505.90075162, 38751.27472268, 73142.9394788 ,\n",
              "       43616.03847094, 28526.91175363, 43306.45155085, 50727.78930822,\n",
              "       46073.35594772, 68617.40095389, 48645.83001415, 53385.98898261])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy \n",
        "r2_score(y_test,y_pred_s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sEyuBPCmBmV",
        "outputId": "ee0c5f42-8cde-4430-9911-2a3b93fa9f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6357729421143091"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the alpha value for which r^2 value is maximum, we use validation curve"
      ],
      "metadata": {
        "id": "el90y_1Tpr5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import validation_curve"
      ],
      "metadata": {
        "id": "t9xeGlyXmdF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_range=np.logspace(-2,8,100)\n",
        "param_range"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osW8xdKgoEBo",
        "outputId": "c6c9ada6-cd4e-47bb-ef88-66e554623e59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.00000000e-02, 1.26185688e-02, 1.59228279e-02, 2.00923300e-02,\n",
              "       2.53536449e-02, 3.19926714e-02, 4.03701726e-02, 5.09413801e-02,\n",
              "       6.42807312e-02, 8.11130831e-02, 1.02353102e-01, 1.29154967e-01,\n",
              "       1.62975083e-01, 2.05651231e-01, 2.59502421e-01, 3.27454916e-01,\n",
              "       4.13201240e-01, 5.21400829e-01, 6.57933225e-01, 8.30217568e-01,\n",
              "       1.04761575e+00, 1.32194115e+00, 1.66810054e+00, 2.10490414e+00,\n",
              "       2.65608778e+00, 3.35160265e+00, 4.22924287e+00, 5.33669923e+00,\n",
              "       6.73415066e+00, 8.49753436e+00, 1.07226722e+01, 1.35304777e+01,\n",
              "       1.70735265e+01, 2.15443469e+01, 2.71858824e+01, 3.43046929e+01,\n",
              "       4.32876128e+01, 5.46227722e+01, 6.89261210e+01, 8.69749003e+01,\n",
              "       1.09749877e+02, 1.38488637e+02, 1.74752840e+02, 2.20513074e+02,\n",
              "       2.78255940e+02, 3.51119173e+02, 4.43062146e+02, 5.59081018e+02,\n",
              "       7.05480231e+02, 8.90215085e+02, 1.12332403e+03, 1.41747416e+03,\n",
              "       1.78864953e+03, 2.25701972e+03, 2.84803587e+03, 3.59381366e+03,\n",
              "       4.53487851e+03, 5.72236766e+03, 7.22080902e+03, 9.11162756e+03,\n",
              "       1.14975700e+04, 1.45082878e+04, 1.83073828e+04, 2.31012970e+04,\n",
              "       2.91505306e+04, 3.67837977e+04, 4.64158883e+04, 5.85702082e+04,\n",
              "       7.39072203e+04, 9.32603347e+04, 1.17681195e+05, 1.48496826e+05,\n",
              "       1.87381742e+05, 2.36448941e+05, 2.98364724e+05, 3.76493581e+05,\n",
              "       4.75081016e+05, 5.99484250e+05, 7.56463328e+05, 9.54548457e+05,\n",
              "       1.20450354e+06, 1.51991108e+06, 1.91791026e+06, 2.42012826e+06,\n",
              "       3.05385551e+06, 3.85352859e+06, 4.86260158e+06, 6.13590727e+06,\n",
              "       7.74263683e+06, 9.77009957e+06, 1.23284674e+07, 1.55567614e+07,\n",
              "       1.96304065e+07, 2.47707636e+07, 3.12571585e+07, 3.94420606e+07,\n",
              "       4.97702356e+07, 6.28029144e+07, 7.92482898e+07, 1.00000000e+08])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_score,test_score=validation_curve(Ridge(),x_train_s,y_train,param_name=\"alpha\",param_range=param_range,scoring='r2')"
      ],
      "metadata": {
        "id": "pkNNn5WjoS7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_score)\n",
        "print(test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLoRuucBo-jj",
        "outputId": "6b4fbc3a-dc79-452c-f0ae-b15518bad28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.36342052e-01 6.95485976e-01 6.90438115e-01 6.79608641e-01\n",
            "  7.47544918e-01]\n",
            " [7.36341888e-01 6.95485186e-01 6.90437301e-01 6.79607548e-01\n",
            "  7.47543956e-01]\n",
            " [7.36341631e-01 6.95483950e-01 6.90436029e-01 6.79605839e-01\n",
            "  7.47542451e-01]\n",
            " [7.36341229e-01 6.95482026e-01 6.90434050e-01 6.79603179e-01\n",
            "  7.47540107e-01]\n",
            " [7.36340603e-01 6.95479048e-01 6.90430989e-01 6.79599063e-01\n",
            "  7.47536478e-01]\n",
            " [7.36339633e-01 6.95474471e-01 6.90426287e-01 6.79592737e-01\n",
            "  7.47530899e-01]\n",
            " [7.36338138e-01 6.95467496e-01 6.90419129e-01 6.79583100e-01\n",
            "  7.47522394e-01]\n",
            " [7.36335855e-01 6.95456977e-01 6.90408348e-01 6.79568572e-01\n",
            "  7.47509562e-01]\n",
            " [7.36332399e-01 6.95441316e-01 6.90392319e-01 6.79546950e-01\n",
            "  7.47490446e-01]\n",
            " [7.36327226e-01 6.95418355e-01 6.90368859e-01 6.79515257e-01\n",
            "  7.47462398e-01]\n",
            " [7.36319581e-01 6.95385295e-01 6.90335159e-01 6.79469640e-01\n",
            "  7.47421981e-01]\n",
            " [7.36308452e-01 6.95338701e-01 6.90287795e-01 6.79405363e-01\n",
            "  7.47364957e-01]\n",
            " [7.36292517e-01 6.95274626e-01 6.90222887e-01 6.79316974e-01\n",
            "  7.47286443e-01]\n",
            " [7.36270119e-01 6.95188926e-01 6.90136453e-01 6.79198728e-01\n",
            "  7.47181285e-01]\n",
            " [7.36239251e-01 6.95077778e-01 6.90024971e-01 6.79045266e-01\n",
            "  7.47044694e-01]\n",
            " [7.36197589e-01 6.94938329e-01 6.89886085e-01 6.78852486e-01\n",
            "  7.46873059e-01]\n",
            " [7.36142547e-01 6.94769368e-01 6.89719305e-01 6.78618419e-01\n",
            "  7.46664804e-01]\n",
            " [7.36071397e-01 6.94571775e-01 6.89526472e-01 6.78343854e-01\n",
            "  7.46421007e-01]\n",
            " [7.35981425e-01 6.94348612e-01 6.89311771e-01 6.78032483e-01\n",
            "  7.46145587e-01]\n",
            " [7.35870157e-01 6.94104748e-01 6.89081210e-01 6.77690509e-01\n",
            "  7.45844930e-01]\n",
            " [7.35735613e-01 6.93846136e-01 6.88841631e-01 6.77325813e-01\n",
            "  7.45527045e-01]\n",
            " [7.35576538e-01 6.93578909e-01 6.88599476e-01 6.76946949e-01\n",
            "  7.45200482e-01]\n",
            " [7.35392466e-01 6.93308522e-01 6.88359564e-01 6.76562167e-01\n",
            "  7.44873242e-01]\n",
            " [7.35183473e-01 6.93039014e-01 6.88124071e-01 6.76178565e-01\n",
            "  7.44551850e-01]\n",
            " [7.34949477e-01 6.92772409e-01 6.87891756e-01 6.75801336e-01\n",
            "  7.44240592e-01]\n",
            " [7.34689065e-01 6.92508145e-01 6.87657388e-01 6.75432973e-01\n",
            "  7.43940841e-01]\n",
            " [7.34397958e-01 6.92242454e-01 6.87411234e-01 6.75072367e-01\n",
            "  7.43650349e-01]\n",
            " [7.34067251e-01 6.91967626e-01 6.87138494e-01 6.74713706e-01\n",
            "  7.43362364e-01]\n",
            " [7.33681572e-01 6.91671068e-01 6.86818575e-01 6.74345135e-01\n",
            "  7.43064411e-01]\n",
            " [7.33217104e-01 6.91334052e-01 6.86424054e-01 6.73947012e-01\n",
            "  7.42736540e-01]\n",
            " [7.32639262e-01 6.90929902e-01 6.85919141e-01 6.73489533e-01\n",
            "  7.42348741e-01]\n",
            " [7.31899565e-01 6.90421256e-01 6.85257227e-01 6.72929340e-01\n",
            "  7.41857177e-01]\n",
            " [7.30931129e-01 6.89755877e-01 6.84376907e-01 6.72204675e-01\n",
            "  7.41198804e-01]\n",
            " [7.29642141e-01 6.88860440e-01 6.83195672e-01 6.71228600e-01\n",
            "  7.40283915e-01]\n",
            " [7.27906737e-01 6.87631774e-01 6.81600474e-01 6.69879856e-01\n",
            "  7.38986253e-01]\n",
            " [7.25553025e-01 6.85925310e-01 6.79434731e-01 6.67991241e-01\n",
            "  7.37130563e-01]\n",
            " [7.22348524e-01 6.83541009e-01 6.76482151e-01 6.65335930e-01\n",
            "  7.34478076e-01]\n",
            " [7.17984338e-01 6.80207935e-01 6.72449097e-01 6.61613216e-01\n",
            "  7.30711509e-01]\n",
            " [7.12061007e-01 6.75570002e-01 6.66949107e-01 6.56436815e-01\n",
            "  7.25422819e-01]\n",
            " [7.04081079e-01 6.69177205e-01 6.59495405e-01 6.49331021e-01\n",
            "  7.18109029e-01]\n",
            " [6.93455521e-01 6.60488675e-01 6.49509240e-01 6.39741961e-01\n",
            "  7.08183299e-01]\n",
            " [6.79532199e-01 6.48895191e-01 6.36352551e-01 6.27071823e-01\n",
            "  6.95008874e-01]\n",
            " [6.61653409e-01 6.33768075e-01 6.19391208e-01 6.10741320e-01\n",
            "  6.77961111e-01]\n",
            " [6.39244296e-01 6.14537040e-01 5.98088439e-01 5.90278590e-01\n",
            "  6.56516176e-01]\n",
            " [6.11924152e-01 5.90790791e-01 5.72116982e-01 5.65421466e-01\n",
            "  6.30354544e-01]\n",
            " [5.79619611e-01 5.62382307e-01 5.41465667e-01 5.36208363e-01\n",
            "  5.99456118e-01]\n",
            " [5.42647966e-01 5.29510626e-01 5.06507911e-01 5.03027506e-01\n",
            "  5.64157481e-01]\n",
            " [5.01738298e-01 4.92749433e-01 4.68003206e-01 4.66601268e-01\n",
            "  5.25146909e-01]\n",
            " [4.57972882e-01 4.53004764e-01 4.27021029e-01 4.27902505e-01\n",
            "  4.83390968e-01]\n",
            " [4.12657933e-01 4.11407321e-01 3.84803534e-01 3.88024818e-01\n",
            "  4.40011111e-01]\n",
            " [3.67158208e-01 3.69168502e-01 3.42605395e-01 3.48045275e-01\n",
            "  3.96146903e-01]\n",
            " [3.22740353e-01 3.27440435e-01 3.01554155e-01 3.08917058e-01\n",
            "  3.52843702e-01]\n",
            " [2.80460359e-01 2.87213217e-01 2.62560757e-01 2.71412111e-01\n",
            "  3.10986722e-01]\n",
            " [2.41108559e-01 2.49262868e-01 2.26286804e-01 2.36111256e-01\n",
            "  2.71280708e-01]\n",
            " [2.05204666e-01 2.14143260e-01 1.93155692e-01 2.03423538e-01\n",
            "  2.34258236e-01]\n",
            " [1.73024659e-01 1.82204621e-01 1.63386893e-01 1.73613906e-01\n",
            "  2.00296765e-01]\n",
            " [1.44641819e-01 1.53621988e-01 1.37035965e-01 1.46825973e-01\n",
            "  1.69632451e-01]\n",
            " [1.19970503e-01 1.28424148e-01 1.14031153e-01 1.23097055e-01\n",
            "  1.42369325e-01]\n",
            " [9.88075952e-02 1.06520735e-01 9.42046477e-02 1.02369548e-01\n",
            "  1.18488706e-01]\n",
            " [8.08700237e-02 8.77284777e-02 7.73198561e-02 8.45038298e-02\n",
            "  9.78638950e-02]\n",
            " [6.58277512e-02 7.17974560e-02 6.30960270e-02 6.92952168e-02\n",
            "  8.02816596e-02]\n",
            " [5.33315339e-02 5.84367281e-02 5.12303629e-02 5.64942405e-02\n",
            "  6.54683456e-02]\n",
            " [4.30348068e-02 4.73376193e-02 4.14168494e-02 4.58275800e-02\n",
            "  5.31166796e-02]\n",
            " [3.46094659e-02 3.81929812e-02 3.33609642e-02 3.70168575e-02\n",
            "  4.29096129e-02]\n",
            " [2.77559271e-02 3.07114597e-02 2.67899207e-02 2.97934437e-02\n",
            "  3.45389677e-02]\n",
            " [2.22083425e-02 2.46267308e-02 2.14587144e-02 2.39086317e-02\n",
            "  2.77182182e-02]\n",
            " [1.77361071e-02 1.97023493e-02 1.71526802e-02 1.91394880e-02\n",
            "  2.21898895e-02]\n",
            " [1.41427960e-02 1.57332029e-02 1.36874614e-02 1.52912101e-02\n",
            "  1.77286585e-02]\n",
            " [1.12635215e-02 1.25446134e-02 1.09072621e-02 1.21969758e-02\n",
            "  1.41413901e-02]\n",
            " [8.96147826e-03 9.98999331e-03 8.68211900e-03 9.71619200e-03\n",
            "  1.12652240e-02]\n",
            " [7.12421586e-03 7.94776288e-03 6.90474014e-03 7.73186572e-03\n",
            "  8.96459118e-03]\n",
            " [5.65999122e-03 6.31802198e-03 5.48728462e-03 6.14761953e-03\n",
            "  7.12778739e-03]\n",
            " [4.49439984e-03 5.01929285e-03 4.35831353e-03 4.88469193e-03\n",
            "  5.66351355e-03]\n",
            " [3.56738484e-03 3.98551518e-03 3.46003508e-03 3.87912531e-03\n",
            "  4.49762482e-03]\n",
            " [2.83065311e-03 3.16338034e-03 2.74589500e-03 3.07924477e-03\n",
            "  3.57021236e-03]\n",
            " [2.24548769e-03 2.51003054e-03 2.17851751e-03 2.44346610e-03\n",
            "  2.83306429e-03]\n",
            " [1.78092293e-03 1.99111225e-03 1.72797606e-03 1.93843147e-03\n",
            "  2.24750539e-03]\n",
            " [1.41223963e-03 1.57915356e-03 1.37035956e-03 1.53744932e-03\n",
            "  1.78258898e-03]\n",
            " [1.11973470e-03 1.25222676e-03 1.08659552e-03 1.21920482e-03\n",
            "  1.41360202e-03]\n",
            " [8.87722046e-04 9.92855428e-04 8.61491357e-04 9.66703698e-04\n",
            "  1.12084077e-03]\n",
            " [7.03725467e-04 7.87127223e-04 6.82957949e-04 7.66413497e-04\n",
            "  8.88615163e-04]\n",
            " [5.57829250e-04 6.23977384e-04 5.41383840e-04 6.07569073e-04\n",
            "  7.04443650e-04]\n",
            " [4.42157396e-04 4.94612398e-04 4.29132547e-04 4.81613471e-04\n",
            "  5.58404929e-04]\n",
            " [3.50456999e-04 3.92047896e-04 3.40139970e-04 3.81749221e-04\n",
            "  4.42617712e-04]\n",
            " [2.77765622e-04 3.10739023e-04 2.69592659e-04 3.02579229e-04\n",
            "  3.50824366e-04]\n",
            " [2.20146143e-04 2.46285373e-04 2.13671162e-04 2.39819962e-04\n",
            "  2.78058371e-04]\n",
            " [1.74475646e-04 1.95195799e-04 1.69345561e-04 1.90072755e-04\n",
            "  2.20379157e-04]\n",
            " [1.38277504e-04 1.54701175e-04 1.34212770e-04 1.50641680e-04\n",
            "  1.74660943e-04]\n",
            " [1.09587920e-04 1.22605475e-04 1.06367172e-04 1.19388663e-04\n",
            "  1.38424749e-04]\n",
            " [8.68499211e-05 9.71674146e-05 8.42978375e-05 9.46183159e-05\n",
            "  1.09704861e-04]\n",
            " [6.88291929e-05 7.70064491e-05 6.68069014e-05 7.49864384e-05\n",
            "  8.69427524e-05]\n",
            " [5.45472871e-05 6.10281373e-05 5.29447757e-05 5.94273801e-05\n",
            "  6.89028593e-05]\n",
            " [4.32286268e-05 4.83649129e-05 4.19587393e-05 4.70963822e-05\n",
            "  5.46057287e-05]\n",
            " [3.42584716e-05 3.83290934e-05 3.32521548e-05 3.73238309e-05\n",
            "  4.32749798e-05]\n",
            " [2.71495821e-05 3.03756077e-05 2.63521230e-05 2.95789709e-05\n",
            "  3.42952302e-05]\n",
            " [2.15157863e-05 2.40724365e-05 2.08838322e-05 2.34411258e-05\n",
            "  2.71787280e-05]\n",
            " [1.70510225e-05 1.90771744e-05 1.65502215e-05 1.85768780e-05\n",
            "  2.15388936e-05]\n",
            " [1.35127253e-05 1.51184476e-05 1.31158564e-05 1.47219753e-05\n",
            "  1.70693408e-05]\n",
            " [1.07086549e-05 1.19811822e-05 1.03941478e-05 1.16669873e-05\n",
            "  1.35272460e-05]\n",
            " [8.48645805e-06 9.49492661e-06 8.23721941e-06 9.24593417e-06\n",
            "  1.07201647e-05]]\n",
            "[[ 4.52060530e-01  7.16533958e-01  7.28178627e-01  7.57173328e-01\n",
            "   4.99304315e-01]\n",
            " [ 4.52045509e-01  7.16542327e-01  7.28201595e-01  7.57217891e-01\n",
            "   4.99328178e-01]\n",
            " [ 4.52027056e-01  7.16552391e-01  7.28229947e-01  7.57273121e-01\n",
            "   4.99357639e-01]\n",
            " [ 4.52004551e-01  7.16564324e-01  7.28264750e-01  7.57341262e-01\n",
            "   4.99393809e-01]\n",
            " [ 4.51977362e-01  7.16578215e-01  7.28307173e-01  7.57424860e-01\n",
            "   4.99437905e-01]\n",
            " [ 4.51944912e-01  7.16593985e-01  7.28358440e-01  7.57526708e-01\n",
            "   4.99491199e-01]\n",
            " [ 4.51906796e-01  7.16611269e-01  7.28419731e-01  7.57649732e-01\n",
            "   4.99554914e-01]\n",
            " [ 4.51862968e-01  7.16629256e-01  7.28492040e-01  7.57796788e-01\n",
            "   4.99630068e-01]\n",
            " [ 4.51814013e-01  7.16646480e-01  7.28575973e-01  7.57970351e-01\n",
            "   4.99717253e-01]\n",
            " [ 4.51761536e-01  7.16660590e-01  7.28671485e-01  7.58172093e-01\n",
            "   4.99816335e-01]\n",
            " [ 4.51708661e-01  7.16668108e-01  7.28777595e-01  7.58402367e-01\n",
            "   4.99926122e-01]\n",
            " [ 4.51660643e-01  7.16664277e-01  7.28892126e-01  7.58659649e-01\n",
            "   5.00044029e-01]\n",
            " [ 4.51625539e-01  7.16643050e-01  7.29011572e-01  7.58940069e-01\n",
            "   5.00165844e-01]\n",
            " [ 4.51614831e-01  7.16597371e-01  7.29131208e-01  7.59237162e-01\n",
            "   5.00285711e-01]\n",
            " [ 4.51643874e-01  7.16519770e-01  7.29245536e-01  7.59541995e-01\n",
            "   5.00396443e-01]\n",
            " [ 4.51732003e-01  7.16403298e-01  7.29349121e-01  7.59843755e-01\n",
            "   5.00490211e-01]\n",
            " [ 4.51902211e-01  7.16242631e-01  7.29437716e-01  7.60130713e-01\n",
            "   5.00559558e-01]\n",
            " [ 4.52180404e-01  7.16035100e-01  7.29509471e-01  7.60391372e-01\n",
            "   5.00598545e-01]\n",
            " [ 4.52594455e-01  7.15781354e-01  7.29565915e-01  7.60615474e-01\n",
            "   5.00603778e-01]\n",
            " [ 4.53173418e-01  7.15485465e-01  7.29612463e-01  7.60794612e-01\n",
            "   5.00575066e-01]\n",
            " [ 4.53947324e-01  7.15154444e-01  7.29658278e-01  7.60922344e-01\n",
            "   5.00515607e-01]\n",
            " [ 4.54947833e-01  7.14797283e-01  7.29715522e-01  7.60993881e-01\n",
            "   5.00431735e-01]\n",
            " [ 4.56209732e-01  7.14423714e-01  7.29798114e-01  7.61005506e-01\n",
            "   5.00332335e-01]\n",
            " [ 4.57772909e-01  7.14042784e-01  7.29920137e-01  7.60953826e-01\n",
            "   5.00228083e-01]\n",
            " [ 4.59684197e-01  7.13661331e-01  7.30094019e-01  7.60834904e-01\n",
            "   5.00130615e-01]\n",
            " [ 4.61998494e-01  7.13282357e-01  7.30328512e-01  7.60643199e-01\n",
            "   5.00051686e-01]\n",
            " [ 4.64778775e-01  7.12903352e-01  7.30626465e-01  7.60370245e-01\n",
            "   5.00002322e-01]\n",
            " [ 4.68094865e-01  7.12514598e-01  7.30982325e-01  7.60002997e-01\n",
            "   4.99991930e-01]\n",
            " [ 4.72021090e-01  7.12097491e-01  7.31379377e-01  7.59521722e-01\n",
            "   5.00027162e-01]\n",
            " [ 4.76632910e-01  7.11622789e-01  7.31786718e-01  7.58897244e-01\n",
            "   5.00110223e-01]\n",
            " [ 4.82002447e-01  7.11048565e-01  7.32156038e-01  7.58087209e-01\n",
            "   5.00236138e-01]\n",
            " [ 4.88192488e-01  7.10317450e-01  7.32418186e-01  7.57030930e-01\n",
            "   5.00388381e-01]\n",
            " [ 4.95248194e-01  7.09352569e-01  7.32479319e-01  7.55642337e-01\n",
            "   5.00532287e-01]\n",
            " [ 5.03185547e-01  7.08051511e-01  7.32216143e-01  7.53800634e-01\n",
            "   5.00605732e-01]\n",
            " [ 5.11975628e-01  7.06277860e-01  7.31469410e-01  7.51338543e-01\n",
            "   5.00506912e-01]\n",
            " [ 5.21524230e-01  7.03850272e-01  7.30034881e-01  7.48028490e-01\n",
            "   5.00079584e-01]\n",
            " [ 5.31647087e-01  7.00529964e-01  7.27651389e-01  7.43567932e-01\n",
            "   4.99097018e-01]\n",
            " [ 5.42042404e-01  6.96008550e-01  7.23986947e-01  7.37566196e-01\n",
            "   4.97247183e-01]\n",
            " [ 5.52264451e-01  6.89899471e-01  7.18625811e-01  7.29536881e-01\n",
            "   4.94123393e-01]\n",
            " [ 5.61704659e-01  6.81737466e-01  7.11061971e-01  7.18901798e-01\n",
            "   4.89226359e-01]\n",
            " [ 5.69589068e-01  6.70991501e-01  7.00706765e-01  7.05014035e-01\n",
            "   4.81984808e-01]\n",
            " [ 5.75001944e-01  6.57096500e-01  6.86919170e-01  6.87207681e-01\n",
            "   4.71801067e-01]\n",
            " [ 5.76943598e-01  6.39507485e-01  6.69065129e-01  6.64878341e-01\n",
            "   4.58124207e-01]\n",
            " [ 5.74424939e-01  6.17775096e-01  6.46605903e-01  6.37590272e-01\n",
            "   4.40545419e-01]\n",
            " [ 5.66591681e-01  5.91633986e-01  6.19204837e-01  6.05193370e-01\n",
            "   4.18899617e-01]\n",
            " [ 5.52858686e-01  5.61086496e-01  5.86829973e-01  5.67920410e-01\n",
            "   3.93347201e-01]\n",
            " [ 5.33023950e-01  5.26457712e-01  5.49822234e-01  5.26429686e-01\n",
            "   3.64406725e-01]\n",
            " [ 5.07329252e-01  4.88399561e-01  5.08902258e-01  4.81767548e-01\n",
            "   3.32917948e-01]\n",
            " [ 4.76446170e-01  4.47834180e-01  4.65105539e-01  4.35249672e-01\n",
            "   2.99935610e-01]\n",
            " [ 4.41389719e-01  4.05846957e-01  4.19659929e-01  3.88289384e-01\n",
            "   2.66579432e-01]\n",
            " [ 4.03386164e-01  3.63557738e-01  3.73839243e-01  3.42220549e-01\n",
            "   2.33882599e-01]\n",
            " [ 3.63732886e-01  3.22004718e-01  3.28831264e-01  2.98160969e-01\n",
            "   2.02679804e-01]\n",
            " [ 3.23681431e-01  2.82066158e-01  2.85646505e-01  2.56941837e-01\n",
            "   1.73557412e-01]\n",
            " [ 2.84356757e-01  2.44426669e-01  2.45074240e-01  2.19101935e-01\n",
            "   1.46862934e-01]\n",
            " [ 2.46709084e-01  2.09578152e-01  2.07676204e-01  1.84925694e-01\n",
            "   1.22751988e-01]\n",
            " [ 2.11488015e-01  1.77838520e-01  1.73802267e-01  1.54498802e-01\n",
            "   1.01245809e-01]\n",
            " [ 1.79231273e-01  1.49374464e-01  1.43615416e-01  1.27761516e-01\n",
            "   8.22796449e-02]\n",
            " [ 1.50265992e-01  1.24222272e-01  1.17119712e-01  1.04550912e-01\n",
            "   6.57346976e-02]\n",
            " [ 1.24723329e-01  1.02307134e-01  9.41897042e-02  8.46320597e-02\n",
            "   5.14560099e-02]\n",
            " [ 1.02565946e-01  8.34634480e-02  7.46011495e-02  6.77219130e-02\n",
            "   3.92626454e-02]\n",
            " [ 8.36248609e-02  6.74574076e-02  5.80621335e-02  5.35093072e-02\n",
            "   2.89555812e-02]\n",
            " [ 6.76399943e-02  5.40109030e-02  4.42425678e-02  4.16725530e-02\n",
            "   2.03258838e-02]\n",
            " [ 5.42987299e-02  4.28244371e-02  3.27998066e-02  3.18945209e-02\n",
            "   1.31633123e-02]\n",
            " [ 4.32683597e-02  3.35967667e-02  2.33987792e-02  2.38745559e-02\n",
            "   7.26437104e-03]\n",
            " [ 3.42205071e-02  2.60398646e-02  1.57261030e-02  1.73367853e-02\n",
            "   2.43880185e-03]\n",
            " [ 2.68474785e-02  1.98888857e-02  9.49859013e-03  1.20348969e-02\n",
            "  -1.48601594e-03]\n",
            " [ 2.08716742e-02  1.49076463e-02  4.46715760e-03  7.75390489e-03\n",
            "  -4.66277032e-03]\n",
            " [ 1.60496782e-02  1.08905651e-02  4.17353934e-04  4.30964031e-03\n",
            "  -7.22369149e-03]\n",
            " [ 1.21726579e-02  7.66210859e-03 -2.83234612e-03  1.54672799e-03\n",
            "  -9.28131879e-03]\n",
            " [ 9.06445604e-03  5.07467632e-03 -5.43353417e-03 -6.64296157e-04\n",
            "  -1.09300855e-02]\n",
            " [ 6.57842812e-03  3.00565831e-03 -7.51144957e-03 -2.43022725e-03\n",
            "  -1.22483281e-02]\n",
            " [ 4.59375557e-03  1.35418612e-03 -9.16867841e-03 -3.83845052e-03\n",
            "  -1.33004330e-02]\n",
            " [ 3.01170536e-03  3.79146462e-05 -1.04886807e-02 -4.96000592e-03\n",
            "  -1.41389291e-02]\n",
            " [ 1.75210926e-03 -1.00996895e-03 -1.15389895e-02 -5.85234586e-03\n",
            "  -1.48064189e-02]\n",
            " [ 7.50202331e-04 -1.84341185e-03 -1.23740160e-02 -6.56174137e-03\n",
            "  -1.53372902e-02]\n",
            " [-4.61274377e-05 -2.50580496e-03 -1.30374491e-02 -7.12533490e-03\n",
            "  -1.57591958e-02]\n",
            " [-6.78678470e-04 -3.03194166e-03 -1.35642739e-02 -7.57286267e-03\n",
            "  -1.60943059e-02]\n",
            " [-1.18089285e-03 -3.44965348e-03 -1.39824448e-02 -7.92808153e-03\n",
            "  -1.63603524e-02]\n",
            " [-1.57947390e-03 -3.78116012e-03 -1.43142610e-02 -8.20993963e-03\n",
            "  -1.65714905e-02]\n",
            " [-1.89571061e-03 -4.04417388e-03 -1.45774857e-02 -8.43352971e-03\n",
            "  -1.67390033e-02]\n",
            " [-2.14655433e-03 -4.25279681e-03 -1.47862542e-02 -8.61086094e-03\n",
            "  -1.68718735e-02]\n",
            " [-2.34548931e-03 -4.41824580e-03 -1.49518049e-02 -8.75148090e-03\n",
            "  -1.69772458e-02]\n",
            " [-2.50323342e-03 -4.54943606e-03 -1.50830673e-02 -8.86297514e-03\n",
            "  -1.70607988e-02]\n",
            " [-2.62830048e-03 -4.65344910e-03 -1.51871320e-02 -8.95136721e-03\n",
            "  -1.71270427e-02]\n",
            " [-2.72745016e-03 -4.73590718e-03 -1.52696277e-02 -9.02143826e-03\n",
            "  -1.71795585e-02]\n",
            " [-2.80604730e-03 -4.80127237e-03 -1.53350206e-02 -9.07698212e-03\n",
            "  -1.72211881e-02]\n",
            " [-2.86834847e-03 -4.85308482e-03 -1.53868536e-02 -9.12100830e-03\n",
            "  -1.72541862e-02]\n",
            " [-2.91773006e-03 -4.89415264e-03 -1.54279369e-02 -9.15590372e-03\n",
            "  -1.72803413e-02]\n",
            " [-2.95686975e-03 -4.92670278e-03 -1.54604987e-02 -9.18356115e-03\n",
            "  -1.73010716e-02]\n",
            " [-2.98789083e-03 -4.95250110e-03 -1.54863060e-02 -9.20548133e-03\n",
            "  -1.73175018e-02]\n",
            " [-3.01247673e-03 -4.97294765e-03 -1.55067595e-02 -9.22285405e-03\n",
            "  -1.73305237e-02]\n",
            " [-3.03196203e-03 -4.98915232e-03 -1.55229695e-02 -9.23662247e-03\n",
            "  -1.73408440e-02]\n",
            " [-3.04740467e-03 -5.00199497e-03 -1.55358163e-02 -9.24753424e-03\n",
            "  -1.73490231e-02]\n",
            " [-3.05964326e-03 -5.01217300e-03 -1.55459975e-02 -9.25618196e-03\n",
            "  -1.73555052e-02]\n",
            " [-3.06934247e-03 -5.02023920e-03 -1.55540663e-02 -9.26303534e-03\n",
            "  -1.73606424e-02]\n",
            " [-3.07702915e-03 -5.02663170e-03 -1.55604607e-02 -9.26846666e-03\n",
            "  -1.73647136e-02]\n",
            " [-3.08312084e-03 -5.03169775e-03 -1.55655284e-02 -9.27277097e-03\n",
            "  -1.73679400e-02]\n",
            " [-3.08794850e-03 -5.03571259e-03 -1.55695444e-02 -9.27618212e-03\n",
            "  -1.73704969e-02]\n",
            " [-3.09177438e-03 -5.03889432e-03 -1.55727271e-02 -9.27888542e-03\n",
            "  -1.73725233e-02]\n",
            " [-3.09480636e-03 -5.04141582e-03 -1.55752494e-02 -9.28102777e-03\n",
            "  -1.73741291e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mean=np.mean(test_score, axis=1)\n",
        "train_mean=np.mean(train_score,axis=1)"
      ],
      "metadata": {
        "id": "C_AglxerqPKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max(test_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBM25iVYtnyU",
        "outputId": "53b784a2-9abf-48e6-a276-20da663e8426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6407034912553751"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x=np.log(param_range),y=test_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FP10wNQht24W",
        "outputId": "516339d3-b7a7-4079-a4f8-2794227eb207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f5409f91b90>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to find the loction of max test_mean in param_range\n",
        "np.where(test_mean==max(test_mean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGtxknCtuGyM",
        "outputId": "b79872b8-a2af-4cbb-9a24-51bdfd907236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([35]),)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_range[35]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swo0IvjguP62",
        "outputId": "e086fdcf-bfec-4b4c-c39f-edc8f04deec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.30469286314919"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model training using the best alpha value for greater accuracy"
      ],
      "metadata": {
        "id": "e0VG_ByiqfAG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model training using ridge\n",
        "rd_best=Ridge(alpha=param_range[35])\n",
        "rd_best.fit(x_train_s,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb6g4eJJuWmM",
        "outputId": "dbd761c4-a100-4fec-cfce-fb5a0c911b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ridge(alpha=34.30469286314919)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "r2_score(y_test,rd_best.predict(x_test_s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGG47OrKrHb0",
        "outputId": "d1375177-db13-422e-e8ee-e52481be2b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6408784721817569"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train,rd_best.predict(x_train_s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ocq7OCzutLd",
        "outputId": "b72c91ad-55f5-4374-baab-10eedad7eb77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.695293521696044"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.Lasso"
      ],
      "metadata": {
        "id": "wKnFC_d8rYnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "ls=Lasso(alpha=0.4)\n",
        "ls.fit(x_train_s,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09DgVRrrvR_u",
        "outputId": "641ab0fe-ae4f-4609-bc6d-4f09b3a7ee4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.197e+10, tolerance: 1.088e+07\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=0.4)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find the alpha value for which r^2 value is maximum, we use validation curve"
      ],
      "metadata": {
        "id": "vIRiy_vorlnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_lsc,test_lsc=validation_curve(Lasso(),x_train_s,y_train,param_name='alpha',param_range=param_range,scoring='r2')\n",
        "train_ls_mean=np.mean(train_lsc,axis=1)\n",
        "test_lsc_mean=np.mean(test_lsc,axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRSqomijwGPt",
        "outputId": "e49ee689-e698-45a3-a83a-d015bbffab22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.187e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.173e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.152e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.138e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.120e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.098e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+10, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.994e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.534e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.000e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.389e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.706e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.959e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.167e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.353e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.543e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.767e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.052e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.417e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.783e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+09, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.750e+08, tolerance: 9.181e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.385e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.369e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.356e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.347e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.335e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.303e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.281e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.254e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.221e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.181e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.133e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.076e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.009e+10, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.324e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.464e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.522e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.519e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.487e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.464e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.493e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.614e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+09, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.662e+08, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.276e+08, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.049e+08, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.220e+07, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.256e+07, tolerance: 9.143e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.295e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.289e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.278e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.271e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.251e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.237e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.219e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.171e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.139e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.100e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.053e+10, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.979e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.338e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.606e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.789e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.901e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.964e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.007e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.069e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.187e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.394e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.715e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+09, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.415e+08, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.570e+08, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+08, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.343e+07, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.467e+07, tolerance: 8.442e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.342e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.340e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.338e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.334e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.330e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.325e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.311e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.200e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.122e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+10, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.415e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.628e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.756e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.816e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.833e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.842e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.881e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.991e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.542e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.015e+09, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.205e+08, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.436e+08, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.642e+08, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.026e+07, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.831e+07, tolerance: 8.427e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.041e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.035e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.026e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.020e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.012e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.003e+10, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.906e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.758e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.574e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.350e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.076e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.747e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.354e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.893e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.359e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.753e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.081e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.357e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.599e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.834e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.092e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.402e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.789e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+09, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.570e+08, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.420e+08, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.168e+08, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+08, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.390e+07, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.385e+07, tolerance: 8.322e+06\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(test_lsc_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sg8al5OxLyw",
        "outputId": "60fd1026-85a9-47bd-ced7-335ef829d258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6358097798977403"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x=np.log(param_range),y=test_lsc_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yuY0a6jax1BC",
        "outputId": "d9c7dff8-c2f4-427a-8bb4-45cdf0e1cdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f5409e38310>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(test_lsc_mean==max(test_lsc_mean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcDj_081yGdk",
        "outputId": "e563f857-e650-45a9-8d9e-07e6836def04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([44]),)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_range[44]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuteM--cyXYt",
        "outputId": "e1cbef96-fac6-44a3-f9dc-7f39aba493f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "278.2559402207126"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model training using Lasso\n",
        "ls_best=Lasso(alpha=param_range[44])\n",
        "ls_best.fit(x_train_s,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN5JLgUnybJM",
        "outputId": "44f6a3f2-a4b7-4033-ae6d-0b9e3dc0c8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Lasso(alpha=278.2559402207126)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model testing/prediction\n",
        "r2_score(y_test,ls_best.predict(x_test_s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isafvVTxrrQ_",
        "outputId": "75642aa9-ffe2-4bf5-e0b7-cff392a8ceb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6369803779229701"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(y_train,ls_best.predict(x_train_s))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_m5Pq82iy1fj",
        "outputId": "849cea56-6776-4a05-86c5-14912ceb8c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6923236555033697"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    }
  ]
}